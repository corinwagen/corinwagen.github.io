<!DOCTYPE html>
<html>
  <head>
    <title>
      Blog
    </title>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta name="language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="../../static/style.css">

    <link rel="alternate" type="application/rss+xml" title="RSS feed for the blog" href="/rss.xml">

    <!--google-->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MTNZ0ZSG3W"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-MTNZ0ZSG3W');
    </script>

  </head>
  <body>
    <ul class="menu-list">
      <li class="menu-item"><a href="index.html" class="menu-link menu-title">Corin Wagen</a></li>
      <li class="menu-item"><a href="index.html#about" class="menu-link">About</a></li>
      <!--<li class="menu-item"><a href="index.html#projects" class="menu-link">Projects</a></li>-->
      <!--<li class="menu-item"><a href="index.html#past_work" class="menu-link">Past Work</a></li>-->
      <li class="menu-item">
        <a href="blog_p1.html" class="menu-link">Blog</a>
        <a href='archive.html' class="menu-link">(Archive)</a>
      </li>
    </ul>
    <h1 class='blogroll-header'>Blog</h1><div class='next-link'><a href='blog_p2.html'>next page</a></div><br><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20250709_montaillou.html'>Book Review: Montaillou</a></h2><i>July 9, 2025</i>
<p>
The past is powerful evidence for arguments about the present. Since the time of Livy and Tacitus, it’s been common to cite history to advance some ideological, cultural, or political idea. While there’s nothing wrong with this in principle, these lines of discourse often break down because (1) people know very little history and (2) what little history they do know is usually wrong. 
</p>

<p>
  Popular understanding of history is shaped mostly by popular culture: books, movies, and video games. These sources aren’t intrinsically bad—I’ll never remember early modern European states as well as my friend who played hundreds of hours of <i>Europa Universalis IV</i> in high school. But the overall effect of a history education dominated by <i>Gladiator</i>, <i>300</i>, and <i>Ben-Hur</i> is to give people a weird and distorted view of the past,<sup>1</sup> and one inchoate enough to be shaped into almost any argument about the present.
</p>

<p>
If we want to build up a more accurate view of what it was like to live in the past, we want to start with the most fundamental questions: how did people live? How did they spend their time? What did they do for work and for leisure? What did they worry about? Unfortunately, these questions are almost always unanswerable. Most historical documents don’t touch on the daily life of average people, focusing instead on chronicling noble deeds, recording economic transactions, and so on. 
</p>

<p>
But exceptions can be found. The village of Montaillou is a small, mountainous village of about 250 inhabitants in the French Pyrenees (in Occitania, what was then the Duchy of Foix and is today the department of Ariège). Montaillou was remote and unexceptional in almost every way, making it exactly the sort of place which we’d never expect to see in historical documents—except that by 1300 it was one of the last strongholds of Catharism, a Christian heresy which had been almost completely eliminated by the Albigensian Crusade in the 1210s. 
</p>

<p>
This is typical of historical mountain societies. In his landmark work <i>The Mediterranean and the Mediterranean World in the Age of Philip II</i>, Fernand Braudel writes (pp. 38–39): 
</p>

<blockquote>
  There can be no doubt that the lowland, urban civilization penetrated to the highland world very imperfectly and at a very slow rate… for the simple reason that mountains are mountains: that is, primarily an obstacle, and therefore also a refuge, a land of the free. For there men can live out of reach of the pressures and tyrannies of civilization: its social and political order, its monetary economy.
</blockquote>

<p>
  The Cathars who had come to the mountains to flee persecution were dualist Gnostics who believed in the reincarnation of the soul. Their clerics and leaders, called goodmen (<i>bonhommes</i>) or <i>parfaits</i>, were celibate and refused to eat meat or drink wine. Ordinary Cathar followers didn’t hold themselves to this standard until their deathbed, when they would convert to Catharism in a ritual called the <i>consolamentum</i> and then completely fast until dying of hunger (called the <i>endura</i>). Cathars rejected the sacraments, mocked the priests and rituals of the Church, and saw themselves as the true worshipers of the Christian God.
</p>

<p>
  Following the Albigensian Crusade, Montaillou and other rural towns became a refuge for Catharism. This eventually drew the attention of the French Inquisition in the person of Jacques Fournier, bishop of Pamiers. In 1320, Fornier arrested a large percentage of the population of Montaillou and interrogated them at length, recording “substantial and very detailed evidence” (xiv) about their lives. During his tenure at Pamiers, Fournier’s inquisition court investigated 578 people over 370 different days, with scribes and notaries keeping a detailed record of all proceedings in what is now known as the Fournier Register. This extraordinary document might have been lost to history except for the fact that Fournier became <a href=https://en.wikipedia.org/wiki/Pope_Benedict_XII>Pope Benedict XII</a> in 1334 and the Fournier Register was brought to the Vatican Library. 
</p>

<p>
  The Fournier Register was revisited by Annales historian Emmanuel Le Roy Ladurie. His 1975 work <i>Montaillou, village occitan de 1294 à 1324</i> uses the details contained in the Register to reconstruct the world of Montaillou: who the people were, what they thought about, and how they lived. I originally read this book right before starting college and liked it a lot. Recently, I’ve found myself thinking back to Montaillou in everyday discussions about history and decided to read Le Roy Ladurie’s book again. 
</p>

<p>
In this post, I hope to give a taste of the world of Montaillou, and how surprisingly normal (or abnormal) aspects of this world can seem to modern sensibilities. I’m focusing on the questions that interested me the most in this reading, and have omitted a lot of interesting characters and life histories for the sake of space and focus. If you find this review interesting, you should certainly pick up the book yourself—I’ve indicated page numbers in <a href=https://www.amazon.com/Montaillou-Promised-Emmanuel-Roy-Ladurie/dp/0807615986>the 30th anniversary edition</a> for easy reference.
</p>

<h2>Setting</h2>

<p>
Montaillou was (and is) a small village on the French side of the Pyrenees, at an elevation of approximately 4500 feet. In a physical and economic sense, Montaillou was incredibly isolated. There was essentially no non-foot traffic in or out of the village, so goods were carried by hand or with a mule. Montaillou had no blacksmith or tailor, and iron tools were rare (7). Montaillou was too small to have its own mill, so villagers would take wheat by mule to the larger town of Ax-les-Thermes, grind it at the mill, and return with flour, about 10 miles by Google Maps (9). 
</p>

<p>
  Here's a picture of modern Montaillou from Wikipedia. The ruins of medieval Montaillou are visible at the top of the hill, and the snow-capped Pyrenees are visible some 20 miles to the south.
</p>

<figure>
  <img class=centered-img src="../img/20250709_montaillou.jpg" style="width:700px;" />
  <figcaption>Montaillou in April 2005. <a href=https://commons.wikimedia.org/wiki/File:Montaillou_28-04-05_8.jpg>See Wikimedia for higher resolution.</a></figcaption>
</figure>


<p>
The bulk of calories came from bread (made from wheat or millet), and cheese was the primary protein source (8–9). Other documented animal foods include mutton, bacon, goat’s liver, eggs, and trout (9, 82, 83, 124). Cabbages, leeks, broad beans, and turnips were the most common vegetables (9). Most people in Montaillou farmed and raised animals: pigs, cows, sheep, chickens, geese, and so on. Almost everyone kept sheep, but there were some skilled itinerant “professional” shepherds who travelled across the Pyrenees living in the mountains and supervising large herds (69–135), stopping back home from season to season.
</p>

<p>
Apart from the coinage that they used, the people of Montaillou were not “French” in any meaningful sense. They spoke a dialect of Occitanian that was distinct to their region, “about a thousand people at the most” (286). When forced to flee religious persecution, villagers went not to other regions of France but to Catalonia, Lombardy, Sicily, or Valencia (286). They almost always married within their village; in the cases where someone from Montaillou married someone from the outside, it was almost always from a neighboring village (183). Thus the world of Montaillou was, in a personal sense, very small indeed.
</p>


<h2>Housing and Personal Space</h2>

<p>
  The house (<i>domus</i> in Latin, <i>ostal</i> in Occitan) was the fundamental physical and social unit of Montaillou. Physically, the kitchen was the central room of the house, and perhaps the only one built of stone (39). The hearth and cooking utensils were in the middle of the kitchen, hams hung from the roof, and a table and chairs were off to the side (37–38). A cellar was often adjacent to the kitchen (38).
</p>

<p>
Personal space was not as scarce as people sometimes imagine in medieval times. Most rooms had only one or two people, and people had separate beds (38–39). Children and adults slept in separate rooms (39). Most houses only had one story, but richer villagers might have two-story houses (39). Animals typically slept in the house at night, albeit in separate rooms, and used the same door as people; sick people were sometimes put near animals to keep them warm at night. Only relatively wealthy farms had separate stables, pigsties, and sheep-pens (40). 
</p>

<p>
  The intellectual and social life of Montaillou revolved around the <i>domus</i>, “a unifying concept in social, family, and cultural life” (25). When villagers discussed Catharism and Catholicism, they identified beliefs not with individuals but with houses (28). To be the head of the house was a significant position of authority; to have one’s house confiscated or destroyed was cataclysmic (35–37). 
</p>

<figure>
  <img class=centered-img src="../img/20250709_feb.png" style="width:400px;" />
  <figcaption> Detail of the February scene from the <i>Très Riches Heures du Duc de Berry</i> (c. 1415)</figcaption>
</figure>


<h2>Family</h2>

<p>
It’s become somewhat popular in recent years to argue against the primacy of the nuclear family. In his 2020 article “<a href=https://www.theatlantic.com/magazine/archive/2020/03/the-nuclear-family-was-a-mistake/605536/>The Nuclear Family Was a Mistake</a>”, David Brooks argues that “big, interconnected, and extended families” are the historical norm and a healthier & more natural way to live. I’ve thought about this essay and argued about it with friends many times over the past few years; in fact, these arguments were a large part of why I originally wanted to reread Montaillou. 
</p>

<p>
I expected the history of Montaillou to support Brooks’s position that extended families were more normal than nuclear families in medieval societies, but it didn’t. The vast majority of houses held nuclear families, or nuclear-ish families where an uncle or grandmother lived with the core family unit. Several examples of more extended families are documented, but they are “very rare cases” and usually unstable (48). As a rule, there was only one married couple per house and the house organized itself around this couple. 
</p>

<p>
Montaillou was largely patriarchal, but not entirely so. There were maternal houses where the sons took their mother’s name and son-in-laws took their wife’s name (34). Nor was primogeniture absolute. Fathers generally determined who inherited the house, but the inheritor did not have to be the firstborn, and the other sons would receive a smaller portion called a fratrisia (36). Both these facts surprised me. 
</p>

<p>
Marriage was typically arranged by the family and “involved much more than a mere agreement between two individuals” (180), with numerous relatives often involved. Dowries were substantial enough that families worried that marrying their daughters might bring economic ruin upon their houses, but remained the distinct property of the wife after marriage. If the husband died first, the widow retained her dowry separately from whomever might inherit the rest of the possessions (35–36).
</p>

<p>
Widows were common because women were typically married young, between the ages of 15 and 20, while men typically waited until after 25 to marry (190). Le Roy Ladurie writes (191): 
</p>

<blockquote>
Husbands in Montaillou were generally fully adult and they often married young innocents. The girls were beginners; the men were settling down. This difference in age in a world where people died young soon produced a crop of young widows. With one husband in the grave, women prepared to go through one or even two more marriages.
</blockquote>

<p>
While marriage for love was not the primary objective, neither was it impossible: “it was possible to love passionately within apparently rigid structures which predisposed towards and presided over the choice of a marriage partner” (187). That being said, the sources rarely speak of women’s feelings towards their husbands (189):
</p>

<blockquote>
It is probably, and sometimes provable, that the young men in love whom we find in the Register aroused similar feelings in the girls they married. But references are scarce. Rightly or wrongly, in upper Ariège the man was supposed to possess the initiative or even the monopoly in matters of love and affection, at least in the realm of courtship and marriage.
</blockquote>

<figure>
  <img class=centered-img src="../img/20250709_jul.png" style="width:400px;" />
  <figcaption> Detail of the July scene from the <i>Très Riches Heures du Duc de Berry</i> (c. 1415)</figcaption>
</figure>


<h2>Stages of Life</h2>

<p>
As might be expected, families in Montaillou were considerably larger than today. Based on data in the Register, Le Roy Ladurie estimates that there were 4.5 legitimate births per family, plus a small but non-negligible number of illegitimate births (204). For all but the wealthiest of families this was an asset: “a domus rich in children was a domus rich in manpower; in other words, rich, pure and simple” (207). Contraception was practiced, especially outside marriage, but not abortion (172–173, 209). Children were nursed for a long time, perhaps until two years old (208).
</p>

<p>
  Modern people sometimes allege that love for young children is a modern phenomenon, citing the Roman <i>paterfamilias</i> as evidence to the contrary. In Montaillou, as today, men and women loved their young children, laughing & playing games with them and weeping bitterly when they died (210–213). The mortality rate for children and adolescents is not clear from our data but “was probably high” (221). Schooling was practical, not formal—children worked with their parents, outside and inside, and were taught religion (Catholic or Cathar) by their families. Children were often put to bed early; the Register records that a six-year-old girl is put to bed before dinner is served to guests (215). 
</p>

<p>
  At the age of 12 or so, boys changed status. The word used to describe them shifts from <i>puer</i> (used from age 2 onwards) to <i>adulescens</i> or <i>juvenis</i>. As adolescents, they began to work as apprentice shepherds, were considered to have reached the age of reason, and could be arrested for heresy (215–216). At 18, men became full-fledged adults (216). I’ll quote Le Roy Ladurie directly on aging (216):
</p>

<blockquote>
When it came to old age, there was a different pattern for men and women. In their thirties, men were in their prime. In their forties, they were still strong. But after about fifty a man was old in those days, and his prestige, unlike that of an elderly woman, did not increase with time. 
</blockquote>


<h2>Friends</h2>

<p>
Domestic servants and hired shepherds were common, and servants often lived in their employers’ houses (115). Labor markets seem quite liquid in this time period—shepherds are often hired for a season and “did not feel this instability as some kind of oppression or alienation” (114). People were part of a market economy, but the 1300s had “easy norms” (124):
</p>

<blockquote>
Everyone who has studied the daily life of the people of Montaillou, whether locals or emigrants, has been struck by the relaxed rhythm of their work, whether they were shepherds, farmers, or artisans… When necessary [a shepherd] got his friends to look after his sheep for him while he went down to the neighbouring town, to take, or to collect, money. Or he might absent himself for purely personal reasons, without any problems of time-keeping or supervision, to go and visit friends, mistresses (unless they came up directly to see him in his cabane) or fellow-sponsors, friends acquired at baptisms recently or long ago…. [He] enjoyed parties and entertainment, and even just a good meal among friends.
</blockquote>


<p>
  The social divide between nobles and non-nobles in Montaillou was not vast. Le Roy Ladurie writes that “ladies and <i>châtelaines</i>, when they met with peasant women, did not hesitate to settle down for a gossip; they might even kiss and embrace” (16). This was likely less true in larger towns or cities; “the absence of strong demarcation between groups can be explained by the relative poverty of the mountain nobility” as contrasted to “the nobles of Paris or Bordeaux, with their huge manorial estates and their vineyards worth their weight in gold” (17). 
</p>

<p>
People had many close, intimate friendships outside the immediate or extended family. Groups of women socialized while fetching water, at the mill, in the kitchen, or sitting in the sun in the village square (251–254). Men met to sing, play chess, or speculate about if Heaven would run out of space for the souls of the dead (259–260). Sunday Mass was the central social event of the week, even for heretics or non-believers, but even so only about half the populace went to Mass any given week (265; 305). 
</p>

<p>
  Even in a village of a few hundred people, it was possible to keep secrets. Heretic <i>parfaits</i> snuck from house to house via secret passages (41) or disguised themselves as woodcutters to move about incognito (75–76), while nosy neighbors peeked through holes in doors or lifted up roofs (which must have been flimsy) to spy on heretical conversations (245; 256). 
</p>

<figure>
  <img class=centered-img src="../img/20250709_mar.png" style="width:400px;" />
  <figcaption> Detail of the March scene from the <i>Très Riches Heures du Duc de Berry</i> (c. 1415)</figcaption>
</figure>

<h2>Religion and Ethics</h2>

<p>
The taxes owed to the nobility were relatively light, particularly compared to the heavy taxes extracted by the Church, and the latter were hated much more than the former (20–23). It was common for people who owed the Church money (including tithes) to be excommunicated (335). The success of Catharism in Montaillou can be largely attributed to the burdensome taxation of the Church, which gave rise to strong anti-clerical feelings far in advance of any theological rationale. I was surprised to learn that indulgences were a part of Catholic religious practice even in the early 1300s, and were hated then too (334). 
</p>

<p>
Many people envision medieval Europe as a theocracy where Catholic morals reigned supreme, either for good or for ill. At least in the case of Montaillou, this wasn’t true—there were lots of mistresses, concubines, prostitution, illegitimate children, and sordid love affairs (45, 151, 169). Homosexuality is not recorded in Montaillou but is documented in the larger cities of Pamiers and Toulouse (144–149). Approximately 10% of couples in Montaillou during this time period were illicit or “living in sin,” and non-marital cohabitation was common enough that a visitor to one house was uncertain if the woman there was the man’s wife or his concubine. Le Roy Ladurie writes (169):
</p>

<blockquote>
If anyone came across a couple openly living together, the reaction was much the same as it would be today. Were they legally married or not? 
</blockquote>

<p>
  Sexual ethics aside,<sup>2</sup> crime was rare. While petty theft was not uncommon and grazing rights were always a source of conflict, Montaillou was an intimate society where “everyone knew everyone else and strangers were easy to find,” making crimes against property rather impractical (329). In cases in which a flock or house was confiscated, it was always under some legal mechanism rather than outright use of force. During the decades covered by the Fournier Register, a single murder and a handful of rapes are recorded—while this significantly exceeds the present on a per capita basis, these events were rare and shocking to the villagers.
</p>

<figure>
  <img class=centered-img src="../img/20250709_nov.png" style="width:400px;" />
  <figcaption> Detail of the November scene from the <i>Très Riches Heures du Duc de Berry</i> (c. 1415)</figcaption>
</figure>

<h2>Culture</h2>

<p>
The Fournier Register excels as a window into peasant culture in the 14th century. Peasants were “fond of abstract thought and even of philosophy and metaphysics” (232), and Le Roy Ladurie remarks on “the lack of social distance between the countryman… and the nobleman, the priest, the merchant, and the master craftsman, in a world where manual labour, especially craftsmanship, was not despised” (232). The primary social engagement was the evening meal, where groups of peasants would sit for hours at benches around the fire remembering village history, discussing the health of people and animals, arguing about the resurrection of the body, or simply gossiping (247, 250). Wine was served, but not to excess—drunkenness is only mentioned in urban contexts in the Fournier Register, and even there rarely (249). 
</p>

<p>
  Books, while rare and expensive, were important and recognized cultural objects—both Cathar <i>parfaits</i> and Catholic priests derived intellectual legitimacy from the possession of books (211, 234–236). It was rare, but not unheard of, for laymen to be able to read: Le Roy Ladurie estimates that four out of the roughly 250 inhabitants of Montaillou were literate (239). As a result most ideas were transmitted orally, and the Cathar <i>parfaits</i> were renowned for their oration and eloquence.
</p>

<p>
I was very surprised to learn that history was virtually unknown in Montaillou. Only in larger cities like Pamiers was Roman antiquity known and discussed, and there only rarely; in Montaillou, history “scarcely went back further than the previous Comte de Foix” (282). The Church filled this void, but imperfectly. Villagers knew almost nothing of Christian history besides Creation, the lives of Mary, Jesus, and the Apostles, and the coming Day of Judgement and the Resurrection (281). As Le Roy Ladurie describes it, “the people of Montaillou lived in a kind of ‘island in time,’ even more cut off from the past than from the future” (282).
</p>

<h2>Conclusion</h2>

<p>
I’ve only scratched the surface of Montaillou here. I haven’t told the story of Pierre Clergue, heretic village priest who had at least nine mistresses (and probably more) and used his brutal authority to crush village rivals; Pierre Maury, itinerant master shepherd with a love of poverty and a fatalist outlook on life; or Béatrice de Planissoles, twice-widowed noblewoman with a proclivity for dramatic love affairs with non-nobles between husbands. I feel some guilt in omitting these thrilling tales from my review, but I don’t think I can do them justice here.
</p>

<p>
What I’ve instead attempted to do here is give the flavor of medieval life as recounted by Le Roy Ladurie. Since this is a microhistory, we have to be cautious about how much we can generalize; Montaillou was different in the 14th century than in the 10th century, and would be different again by the 17th century, to say nothing of how life would be different in Frisia, Andalusia, Calabria, or outside medieval Europe. (If there’s one thing we can learn from Montaillou, it’s that history is big and strange.)
</p>

<p>
Still, I updated a number of my beliefs about the past after reading about Montaillou. Here’s a few common claims that I thought Montaillou directly addressed.
</p>

<ol>
<li>
    <b>“The nuclear family was a mistake.”</b> I discussed this claim from David Brooks above. Per his argument, Montaillou is exactly the sort of place that we might expect to show strong non-nuclear family living patterns, and yet if anything we see the exact opposite. This suggests that nuclear-family structures are more fundamental than Brooks argues (with the important caveat that this is just a single data point).
</li>
<li>
    <b>“Medieval peasants lived miserable lives of suffering, toil, and death.”</b> Strikingly false in the case of Montaillou. Mortality rates were certainly high, but even the subsistence-level farmers and shepherds documented by the Register had active, social, and joyful lives. I’m not convinced that the median person in Montaillou was less happy than the median person today; if anything, possibly the opposite.<sup>3</sup>
</li>
<li>
    <b>“Learning was forgotten in the Dark Ages.”</b> I was surprised by how true this was for Montaillou. There’s been a lot of pushback against misconceptions about the so-called “Dark Ages,” and popular conceptions about the time between the fall of the Western Roman Empire and the Renaissance are usually just wrong (cf. <a href=https://www.amazon.com/World-Late-Antiquity-150-750-Civilization/dp/0393958035>Peter Brown</a>). But the people of Montaillou were ignorant of almost all history, even just a few generations ago in their village. Maybe this was always true in rural areas, but I suspect this would have been much less true in Roman times and, again, stopped being true by the time of the Renaissance and the Reformation.
</li>
<li>
    <b>“Medieval Europe was a Catholic society where people adhered to Christian morals.”</b> I hear this a lot from more traditional Catholic friends, and this is just bonkers. Maybe Montaillou is an edge case—again, village of heretics—but Le Roy Ladurie argues that the heresy was a symptom of disrespect for the Church, not a cause. The fact that 10% of couples were openly unmarried and cohabitating defied all my intuition about medieval Europe.
</li>
</ol>

<p>
I really enjoyed this microhistory and would love to read different accounts of everyday life in medieval Europe—if you have any recommendations, please let me know!
</p>

<br />
<br /> 

<h3>Footnotes</h3>
<ol>
<li>
  As an aside, I’m a big fan of Bret Devereaux’s writing. He does a fantastic job of debunking myths about history, like <a href=https://acoup.blog/2019/05/28/new-acquisitions-not-how-it-was-game-of-thrones-and-the-middle-ages-part-i/>this series on <i>Game of Thrones</i></a> or <a href=https://acoup.blog/category/collections/this-isnt-sparta/>this series on Sparta</a>, and also does a lot of interesting long-form about pre-modern agriculture, textiles, logistics, and so on.
</li>
<li>
  This moral laxity was gone by the 17th century. The Reformation and Counter-Reformation gave rise to an ocean of fierce debates about theology and ethics and created a society which, compared to Montaillou, was much more concerned about matters of orthodoxy and orthopraxy and much less tolerant of any deviancy. Massachusetts Puritanism can be understood as a facet of this transformation, as can the <a href=https://en.wikipedia.org/wiki/Reformation_of_Manners>Reformation of Manners</a>. This change is noted by Le Roy Ladurie, but my interpretation here comes mainly from Diarmid MacCulloch’s book <i>The Reformation</i>.
</li>
<li>
    It’s worth noting that the feudal order as experienced in Montaillou was pretty lax—less rural areas like those around Paris were probably closer to popular depictions of feudal serfdom. I’m not sure which is more “typical” of feudalism, or if that question is even coherent; feudalism is a broad and often misunderstood concept, see <a href=https://www.amazon.com/Feudalism-F-L-Ganshof/dp/058248216X>Ganshof’s book</a> for a good overview.
</li>
</ol>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20250702_workflows.html'>Workflows Are the New Models</a></h2><i>July 2, 2025</i><br />
<br />
<a href="https://x.com/CorinWagen/status/1939695363427893471"><em>Expanded from a post on X</em></a><em>, which I felt didn’t do a good job expressing all of what I meant.</em>

<p>
  The past few years of “AI for life science” has been all about the models: AlphaFold&nbsp;3, neural-network potentials, protein language models, binder generation, docking, co-folding, ADME/tox prediction, and so on.  
  But <a href="https://www.chaidiscovery.com/news/introducing-chai-2">Chai-2</a> (and lots of related work) shows us that the vibes are shifting.  
  Models themselves are becoming just a building block; the real breakthroughs are going to happen at the workflow level, as we learn how to combine these models into robust and performant pipelines.
</p>

<p>
  Workflows are the new models.  
  To have a state-of-the-art computational stack for drug discovery (or protein engineering, or materials design, or anything else), it’s no longer enough to have just a single state-of-the-art model.  
  You need a suite of modular tools that you can combine in a way that makes sense for your task. (At Rowan, we’re seeing this happen all over the industry.)
</p>

<p>What does this mean in practice? Here are two imaginary case studies illustrating what modern computational chemistry looks like in 2025:</p>

<h3>Materials Science</h3>

<p>
  A company is developing a new inorganic photocatalyst for bulk acid–alkene coupling (following
  <a href="https://pubs.acs.org/doi/abs/10.1021/jacs.0c08688">Zhu and Nocera, 2020</a>).  
  Their workflow might look something like this:
</p>

<ul>
  <li>Agentic literature search for potential photo-active inorganic materials that seem synthesizable.</li>
  <li>A diffusion or flow-matching model for 3-D structure generation where crystallography data doesn’t exist.</li>
  <li>Rapid structural relaxation with a neural-network potential (NNP) to generate minimized structures.</li>
  <li>Adsorption-energy estimation with another NNP to see if alkene binding is feasible.</li>
  <li>HOMO–LUMO gap computation with periodic DFT to estimate photo-activity.</li>
  <li>Molecular dynamics to check the stability of the bound pose.</li>
  <li>Volcano-plot creation and final candidate scoring based on all properties.</li>
</ul>

<p>
  The entire cycle can be repeated <em>ad nauseum</em> to generate new candidates, with the focus gradually shifting from exploration to exploitation.
</p>

<h3>Drug Discovery</h3>

<p>
  A company has identified new CNS biological targets that they hope to inhibit with a small molecule.  
  Their workflow might look something like this:
</p>

<ul>
  <li>Based on a starting hit (from a DEL, or from a known binder), generate modifications automatically or by sampling from an enumerated library.</li>
  <li>Filter candidates by synthesizability, solubility, pK<sub>a</sub>, and other project-specific structural filters.</li>
  <li>Dock molecules against the target and potential anti-targets using a fast method like Vina.</li>
  <li>For hits predicted to show good selectivity, rescore with a second method (strain-corrected docking, Boltz-2, etc.).</li>
  <li>
    <a href="https://pubs.acs.org/doi/abs/10.1021/acs.jcim.0c00057">Run a short MD simulation</a> to check the stability of the bound pose.
  </li>
  <li>
    Screen for <a href="https://rowansci.com/publications/macroscopic-pka-prediction">blood–brain-barrier permeability</a> and
    <a href="https://pubs.acs.org/doi/10.1021/acs.chemrestox.4c00015">liver toxicity</a> (e.g.).
  </li>
</ul>

<p>
  This cycle, too, can be repeated until <del>you run out of Modal credits</del> a set of promising candidates is identified for synthesis.
</p>

<br />

<p>
  Neither of these case studies is based on a particular company; instead, they’re meant to illustrate the sort of ML-native workflows we’re seeing from early adopters across the chemical sciences.  
  For simplicity, experimental integration isn’t shown here, but any sane scientist will obviously incorporate wet-lab testing as soon as possible and feed those insights back into the top of the funnel.
</p>

<p>
  In any case, the overall point is clear—no single model can by itself solve every problem, and figuring out the right way to combine a set of models is itself a non-trivial system-design problem.  
  It’s entirely possible to create a state-of-the-art workflow simply by combining “commoditized” open-source models in a new way, and so far the resultant workflows don’t seem obvious or easy to copy.  
  This defies popular intuition about what constitutes a “moat” for AI companies.
</p>

<p>
  More metaphysically, the line between workflows and models is blurring.  
  Many ML-adjacent people think of models as the active unit of science: “they have a model for X” or “we’re building a model for Y.”  
  But, as shown above, most state-of-the-art research today requires lots of individual ML models, and many “models” are already miniature workflows.  
  For instance, running a single inference call through
  <a href="https://github.com/dptech-corp/Uni-pKa">the Uni-pKa “model”</a> requires enumerating all possible microstates, performing a conformer search, and running geometry optimizations on every individual conformer—just to generate the pairwise-distance matrix used as input for the actual ML model.
</p>

<p>Why does this matter? Here are a few thoughts that I've had, after thinking about this point:</p>

<ul>
  <li>Models must be plug-and-play, interoperable, and robust—anything that can’t be integrated into higher-level workflows won’t be used.</li>
  <li>
    The best models might not be those that top isolated benchmarks; in a workflow context, speed, reliability, and uncertainty
    quantification also matter.  
    Richard Hamming’s first rule of systems engineering comes to mind: “If you optimize the components, you will probably ruin the system
    performance” (<a href="https://corinwagen.github.io/public/blog/20230516_hamming.html">see my previous book review</a>).
  </li>
  <li>
    Any thinking that depends on a sharp metaphysical difference between workflows and models is probably wrong.  
    I recently had a sales call where someone told me they weren’t interested in any workflows—they only wanted to use models.  
    I wanted to send them to
    <a href="https://slatestarcodex.com/2014/11/21/the-categories-were-made-for-man-not-man-for-the-categories/">old Slate Star Codex posts</a>,
    but (wisely?) held my tongue.
  </li>
  <li>
    Devops and good software engineering will rise in importance.  
    At Rowan, we’ve learned firsthand how hard it is to manage hundreds of thousands of workflows across a vast sea of unruly scientific dependencies.
  </li>
  <li>
    Relatedly, the amount of scientific, computational, and engineering expertise needed to run a modern computational-science program is
    rising exponentially—and shows no signs of stopping.
  </li>
</ul>

<i>Thanks to Ari Wagen for reading a draft of this post.</i>
</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20250604_good_will_hunting.html'>Teach Yourself Quantum Chemistry (For Fun And Profit)</a></h2><i>June 4, 2025</i>
<figure>
  <img class=centered-img src="../img/20250604_damon.png" style="width:500px;" />
</figure>

<p>“You dropped a hundred and fifty grand on a f***** education you coulda' got for a dollar fifty in late charges at the public library.” —<em>Good Will Hunting</em></p>

<p>I was a user of computational chemistry for years, but one with relatively little understanding of how things actually worked below the input-file level. As I became more interested in computation in graduate school, I realized that I needed to understand everything much more deeply if I hoped to do interesting or original work in this space. From about August 2021 to December 2023, I tried to learn as much about how computational chemistry worked as I could, with the ultimate goal of being able to recreate my entire computational stack from scratch.</p>
<p>I found this task pretty challenging. Non-scientists don’t appreciate just how esoteric and inaccessible scientific knowledge can be: Wikipedia is laughably bad for most areas of chemistry, and most scientific knowledge isn’t listed on Google at all but trapped in bits and pieces behind journal paywalls. My goal in this post is to describe my journey and index some of the most relevant information I’ve found, in the hopes that anyone else hoping to learn about these topics has an easier time than I did.</p>
<p>This post is a directory, not a tutorial. I’m not the right person to explain quantum chemistry from scratch. Many wiser folks than I have already written good explanations, and my hope is simply to make it easier for people to find the “key references” in a given area. This post also reflects my own biases; it’s focused on molecular density-functional theory and neglects post-Hartree–Fock methods, most semiempirical methods, and periodic systems. If this upsets you, consider creating a companion post that fills the lacunæ—I would love to read it!</p>
<h2>0. Background</h2>
<p>I started my journey to understand computational chemistry with roughly three years of practice using computational chemistry. This meant that I already knew how to use various programs (Gaussian, ORCA, xTB, etc), I was actively using these tools in research projects, and I had a vague sense of how everything worked from reading a few textbooks and papers. If you don’t have any exposure to computational chemistry at all—if the acronyms “B3LYP”, “def2-TZVPP”, or “CCSD(T)” mean nothing to you—then this post probably won’t make very much sense.</p>
<p>Fortunately, it’s not too hard to acquire the requisite context. For an introduction to quantum chemistry, a good resource is Chris Cramer's <a href="https://www.youtube.com/watch?v=pu4uL7deCNw&amp;list=PLkNVwyLvX_TFBLHCvApmvafqqQUHb6JwF">video series</a> from his class at UMN. This is pretty basic but covers the main stuff; it's common for one of the classes in the physical chemistry sequence to also cover some of these topics. If you prefer books, <a href="https://www.amazon.com/Essentials-Computational-Chemistry-Theories-Models/dp/0470091827">Cramer</a> and <a href="https://www.amazon.com/Introduction-Computational-Chemistry-Frank-Jensen/dp/0470011874">Jensen</a> have textbooks that go slightly more in depth. </p>
<p>For further reading:</p>
<ul>
  <li>Steve Bachrach has a book on <a href="https://comporgchem.com/">computational organic chemistry</a> which discusses applying these techniques to a variety of problems in organic chemistry.</li>
  <li><a href="https://chemistlibrary.wordpress.com/wp-content/uploads/2015/02/modern-quantum-chemistry.pdf">Szabo/Ostlund</a> and <a href="https://www.amazon.com/Molecular-Electronic-Structure-Theory-Trygve-Helgaker/dp/1118531477">Helgaker/Jorgensen/Olsen</a> go much more into detail on the mathematics and implementation. (I confess I've only read parts of these books.)</li>
</ul>
<p>In general, computational chemistry is a fast-moving field relative to most branches of chemistry, so textbooks will be much less valuable than e.g. organic chemistry. There are lots of good review articles like <a href="https://onlinelibrary.wiley.com/doi/10.1002/anie.202205735">this one</a> which you can use to keep up-to-date with what's actually happening in the field recently, and reading the literature <a href="https://corinwagen.github.io/public/blog/20230329_literature.html">never goes out of style</a>.</p>
<p>All of the above discuss how to learn the theory behind calculations—to actually get experience running some of these, I'd suggest trying to reproduce a reaction that you've seen modeled in the literature. <a href="https://ekwan.github.io/notes.html#computational-chemistry">Eugene Kwan's notes are solid</a> (if Harvard-specific), and there are lots of free open-source programs that you can run like Psi4, PySCF, and xTB. (If you want to use Rowan, <a href="https://docs.rowansci.com/tutorials">we've got a variety of tutorials too.</a>) It's usually easiest to learn to do something by trying to solve a specific problem that you're interested in—I started out trying to model the effect of different ligands on the barrier to Pd-catalyzed C–F reductive elimination, which was tough but rewarding.</p>

<figure>
  <img class=centered-img src="../img/20250604_cf.png" style="width:650px;" />
</figure>

<p>Molecular dynamics is important but won’t be covered further here. The best scientific introduction to MD I've come across is <a href="https://sites.engineering.ucsb.edu/~shell/che210d/">these notes from M. Scott Shell</a>. If you want to go deeper, I really liked <a href="https://www.amazon.com/Understanding-Molecular-Simulation-Applications-Computational/dp/0122673514">Frenkel/Smit</a>; any knowledge of statistical mechanics will be very useful too, although I don’t have any recommendations for stat-mech textbooks. To get started actually running MD, I'd suggest looking into the OpenFF/OpenMM ecosystem, which is free, open-source, and moderately well-documented by scientific standards. (<a href="https://corinwagen.github.io/public/blog/20240613_simple_md.html">I've posted some intro scripts here</a>.)</p>
<p>Cheminformatics is a somewhat vaguely defined field, basically just "data science for chemistry," and it's both important and not super well documented. If you're interested in these topics, I recommend just reading <a href="https://patwalters.github.io/year-archive/">Pat Walters' blog</a> or <a href="https://greglandrum.github.io/rdkit-blog/">Greg Landrum's blog</a>: these are probably the two best cheminformatics resources.</p>
<p>As with all things computational, it's also worth taking time to build up a knowledge of computer science and programming—knowing how to code is an investment which will almost always pay itself back, no matter the field. That doesn't really fit into this guide, but being good at Python/Numpy/data science/scripting is worth pursuing in parallel, if you don't already have these skills.</p>

<h2>1. How do Things Work, Basically?</h2>
<p>I started my computational journey by trying to write my own quantum chemistry code from scratch. My disposition is closer to “tinkerer” than “theorist,” so I found it helpful to start tinkering with algorithms as quickly as possible to give myself <a href="https://marginalrevolution.com/marginalrevolution/2022/02/context-is-that-which-is-scarce-2.html">context</a> for the papers I was trying to read. There are several toy implementations of Hartree–Fock theory out there that are easy enough to read and reimplement yourself:</p>
<ul>
  <li><a href="https://nznano.blogspot.com/2018/03/simple-quantum-chemistry-hartree-fock.html">NZNano</a> has a compact Jupyter notebook that runs an HF/STO-3G calculation on helium hydride.</li>
  <li><a href="https://adambaskerville.github.io/posts/HartreeFockGuide/">Adam Baskerville</a> has a somewhat cleaner implementation of HF/STO-3G on HeH+, albeit one which doesn’t compute the one- and two-electron integrals.</li>
  <li><a href="https://github.com/jjgoings/McMurchie-Davidson">Joshua Goings</a> has a great general implementation of HF for any molecule or basis set, and <a href="https://joshuagoings.com/2017/04/28/integrals/">an associated blog post</a> explaining how to compute the integrals.</li>
</ul>
<p>Based on these programs, I wrote my own Numpy-based implementation of Hartree–Fock theory, and got it to match values from the NIST CCCBDB database.</p>

<pre class=code-block>
  iteration 05:	∆P 0.000001	E_elec -4.201085		∆E -0.000000

SCF done (5 iterations):
-2.83122 Hartree

orbital energies: [-2.30637605 -0.03929435]
orbital matrix: 
[[-0.71874445  0.86025802]
 [-0.44259188 -1.02992712]]
density matrix: 
[[1.03318718 0.63622091]
 [0.63622091 0.39177514]]
Mulliken charges:
[[1.32070648 0.81327091]
 [1.10313469 0.67929352]]
</pre>

<p>I highly recommend this exercise: it makes quantum chemistry much less mysterious, but also illustrates just how slow things can be when done naïvely. For instance, my first program took 49 minutes just to compute the HF/6-31G(d) energy of water, while most quantum chemistry codes can perform that calculation in under a second. Trying to understand this discrepancy was a powerful motivation to keep reading papers and learning new concepts.</p>

<h2>2. Overview</h2>
<p>Armed with a basic understanding of what goes into running a calculation, I next tried to understand how “real” computational chemists structure their software. The best single paper on this topic, in my opinion, is the <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.540030314">“direct SCF” Almlof/Faegri/Korsell paper from 1982</a>. It outlines the basic method by which almost all calculations are run today, and it’s pretty easy to read. (See also <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.540100111">this 1989 followup by Haser and Ahlrichs</a>, and <a href="https://link.springer.com/article/10.1007/s002149900072">this 2000 retrospective by Head-Gordon.</a>)</p>

<figure>
  <img class=centered-img src="../img/20250604_direct_scf.png" style="width:550px;" />
</figure>

<p>I found several other papers very useful for building high-level intuition. <a href="https://rsc.anu.edu.au/~pgill/papers/066ECC.pdf">This overview of self-consistent field theory by Peter Gill</a> is very nice, and <a href="https://schlegelgroup.wayne.edu/Pub_folder/32.pdf">Pople’s 1979 paper</a> on analytical first and second derivatives within Hartree–Fock theory is a must-read. <a href="https://www.worldscientific.com/doi/abs/10.1142/9789812832115_0008?srsltid=AfmBOopXU4ZCfegA2U-8HABNK_sBs_gU29cWUgfwv0diFtmKgs_RC2CF">This 1995 Pulay review</a> is also very good.</p>
<p>Using the intuition in these papers, I was able to outline and build a simple object-oriented Hartree–Fock program in Python. My code (which I called <span class=code>hfpy</span>, in allusion to <a href="https://www.sigmaaldrich.com/US/en/product/aldrich/184225">the reagent</a>) was horribly inefficient, but it was clean and had the structure of a real quantum chemistry program (unlike the toy Jupyter Notebooks above). Here’s some of the code that builds the Fock matrix, for instance:</p>

<pre class=code-block>
    for classname in quartet_classes.keys():
        num_in_class = len(quartet_classes[classname])
        current_idx = 0
        while current_idx &lt; num_in_class:
            batch = ShellQuartetBatch(quartet_classes[classname][current_idx:current_idx+Nbatch])

            # compute ERI
            # returns a matrix of shape A.Nbasis x B.Nbasis x C.Nbasis x D.Nbasis x NBatch
            ERIabcd = eri_MMD(batch)
            shell_quartets_computed += batch.size

            for i, ABCD in enumerate(batch.quartets):
                G = apply_ERI(G, *ABCD.indices, bf_idxs, ERIabcd[:,:,:,:,i], ABCD.degeneracy(), dP)

            current_idx += Nbatch

    # symmetrize final matrix
    # otherwise you mess up, because we've added (10|00) and not (01|00) (e.g.)
    G = (G + G.T) / 2
    if incremental:
        molecule.F += G
    else:
        molecule.F = molecule.Hcore + G

    print(f"{shell_quartets_computed}/{shell_quartets_possible} shell quartets computed")
</code></pre>
<p>Any quantum-chemistry developer will cringe at the thought of passing 5-dimensional ERI arrays around in Python—but from a pedagogical perspective, it’s a good strategy.</p>

<h2>3. Details</h2>
<p>Armed with a decent roadmap of what I would need to build a decent quantum chemistry program, I next tried to understand each component in depth. These topics are organized roughly in the order I studied them, but they’re loosely coupled and can probably be addressed in any order.</p>
<p>As I read about various algorithms, I implemented them in my code to see what the performance impact would be. (By this time, I had rewritten everything in C++, which made things significantly faster.) Here’s a snapshot of what my life looked like back then:</p>
<pre class=code-block>benzene / 6-31G(d)
    12.05.22 - 574.1 s - SHARK algorithm implemented

    12.20.22 - 507.7 s - misc optimization
    12.21.22 - 376.5 s - downward recursion for [0](m)
    12.22.22 - 335.9 s - Taylor series approx. for Boys function
    12.23.22 - 300.7 s - move matrix construction out of inner loops
    12.25.22 - 267.4 s - refactor electron transfer relation a bit
    12.26.22 - 200.7 s - create electron transfer engine, add some references
    12.27.22 - 107.9 s - cache electron transfer engine creation, shared_ptr for shell pairs
    12.28.22 -  71.8 s - better memory management, refactor REngine
    12.29.22 -  67.6 s - more memory tweaks

    01.03.23 -  65.1 s - misc minor changes
    01.05.23 -  56.6 s - create PrimitivePair object
    01.07.23 -  54.7 s - Clementi-style s-shell pruning
    01.08.23 -  51.7 s - reduce unnecessary basis set work upon startup
    01.10.23 -  49.9 s - change convergence criteria
    01.11.23 -  61.1 s - stricter criteria, dynamic integral cutoffs, periodic Fock rebuilds
    01.12.23 -  42.5 s - improved DIIS amidst refactoring

    01.20.23 -  44.7 s - implement SAD guess, poorly
    01.23.23 -  42.6 s - Ochsenfeld's CSAM integral screening
    01.30.23 -  41.7 s - improve adjoined basis set generally

    02.08.23 -  38.2 s - introduce spherical coordinates. energy a little changed, to -230.689906932 Eh.

    02.09.23 -  12.3 s - save ERI values in memory. refactor maxDensityMatrix.
    02.15.23 -   9.0 s - rational function approx. for Boys function
    02.18.23 -   8.7 s - minor memory changes, don't recreate working matrices in SharkEngine each time
</pre>

<p>
  Here's a rough list of the topics I studied, with the references that I found to be most helpful in each area.
</p>

<h3>3.1 ERI Computation</h3>
<p>Writing your own QM code illustrates (in grisly fashion) just how expensive computing electron–electron repulsion integrals (ERIs) can be. This problem dominated the field’s attention for a long time. In the memorable words of Jun Zhang:</p>
<blockquote>
  Two electron repulsion integral. It is quantum chemists’ nightmare and has haunted in quantum chemistry since its birth.
</blockquote>
<p>To get started, Edward Valeev has written <a href="https://arxiv.org/ftp/arxiv/papers/2007/2007.12057.pdf">a good overview of the theory behind ERI computation</a>. For a broad overview of lots of different ERI-related ideas, my favorite papers are these two accounts by <a href="https://rsc.anu.edu.au/~pgill/papers/045Review.pdf">Peter Gill</a> and <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/jcc.26942">Frank Neese</a>. (I’ve probably read parts of Gill’s review almost a hundred times.)</p>
<p>Here are some other good ERI-related papers, in rough chronological order:</p>
<ul>
  <li><a href="https://www.sciencedirect.com/science/article/abs/pii/0009261473800600">This 1973 paper by Raffinetti</a> discusses a non-direct SCF strategy for storing integrals on disk, which is still commonly used for small systems.</li>
  <li><a href="https://pubs.aip.org/aip/jcp/article-abstract/89/9/5777/220762/A-method-for-two-electron-Gaussian-integral-and?redirectedFrom=fulltext">This 1989 paper from Head-Gordon and Pople</a> outlines the basic algorithm by which most programs tackle ERI computation today. (The core ideas were developed by <a href="https://pubs.aip.org/aip/jcp/article-abstract/84/7/3963/91928/Efficient-recursive-computation-of-molecular?redirectedFrom=fulltext">Obara and Saika</a>, but I find that paper pretty unintelligible.) <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.560360831">Peter Gill’s extension of this work</a> is also quite nice (see also his review above).</li>
  <li><a href="https://pubs.aip.org/aip/jcp/article-abstract/104/7/2620/479230/A-J-matrix-engine-for-density-functional-theory?redirectedFrom=fulltext">This 1996 White/Head-Gordon paper</a> proposes the “<em>J</em>-matrix engine” and <a href="https://www.sciencedirect.com/science/article/abs/pii/S0009261400005248">this 2000 paper</a> suggests some enhancements.</li>
  <li>Todd Martínez has a great series of papers discussing ERI evaluation on GPUs: <a href="https://pubs.acs.org/doi/10.1021/ct700268q">1</a>, <a href="https://pubs.acs.org/doi/abs/10.1021/ct800526s">2</a>, <a href="https://pubs.acs.org/doi/10.1021/ct9003004">3</a></li>
  <li>Ochsenfeld and Head-Gordon’s <a href="https://pubs.aip.org/aip/jcp/article-abstract/109/5/1663/529170/Linear-and-sublinear-scaling-formation-of-Hartree?redirectedFrom=fulltext">LinK strategy</a> for accelerated exchange computation is very nice. (And resolution-of-the-identity approaches can help here too: see <a href="https://pubs.aip.org/aip/jcp/article/143/2/024113/825080/Fast-accurate-evaluation-of-exact-exchange-The-occ">Manzer’s “occ-RI-K” strategy</a>.)</li>
  <li><a href="https://pubs.acs.org/doi/abs/10.1021/acs.jctc.7b00788">Jun Zhang has a paper</a> on metaprogramming-based approaches to ERI computation.</li>
  <li>Benjamin Pritchard has <a href="https://onlinelibrary.wiley.com/doi/10.1002/jcc.24483">a paper on vectorization in ERI computation</a>.</li>
  <li>C. David Sherrill discusses permutational symmetry in <a href="http://vergil.chemistry.gatech.edu/notes/permsymm/permsymm.html">these notes</a>.</li>
  <li>Integral screening matters a lot; I discuss it in <a href="https://corinwagen.github.io/public/blog/20230123_integral_screening.html">this blog post</a> from January 2023, which is roughly when I was learning all of this.</li>
</ul>

<h3>3.2 SCF Convergence</h3>
<p>Writing your own QM code also illustrates how important SCF convergence can be. With the most naïve approaches, even 15–20 atom molecules often struggle to converge—and managing SCF convergence is still relatively unsolved in lots of areas of chemistry today, like radicals or transition metals.</p>

<figure>
  <img class=centered-img src="../img/20250604_scf.png" style="width:500px;" />
  <figcaption>
    Different SCF-convergence strategies and how they fare on tricky systems (from Scuseria, <i>JCP</i>, <b>2012</b>; <i>vide infra</i>)
  </figcaption>
</figure>

<p>This is obviously a big topic, but here are a few useful references:</p>
<ul>
  <li><a href="https://schlegelgroup.wayne.edu/Pub_folder/126.pdf">This 1991 review</a> by Schlegel and Douall is a good overview of SCF convergence questions.</li>
  <li>The most fundamental approach is Pulay’s “direct inversion of the iterative subspace” (DIIS): the original paper is <a href="https://www.sciencedirect.com/science/article/abs/pii/0009261480803964?via%3Dihub">here</a>, but this is famous enough that there are plenty of good and more modern summaries out there (<a href="https://joshipulkit.github.io/notes/diis/">1</a>, <a href="http://vergil.chemistry.gatech.edu/notes/diis/node2.html">2</a>, <a href="https://github.com/psi4/psi4numpy/blob/master/Tutorials/03_Hartree-Fock/3b_rhf-diis.ipynb">3</a>).</li>
  <li><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2830258/">This 2010 paper</a> describes the “ADIIS” strategy, and <a href="https://pubs.aip.org/aip/jcp/article-abstract/137/5/054110/671630/Comparison-of-self-consistent-field-convergence?redirectedFrom=fulltext">this 2012 Scuseria paper</a> shows that ADIIS and “energy DIIS” (EDIIS) are equivalent.</li>
  <li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.20393">This 2006 paper</a> is a good guide to the “superposition of atomic density” guess strategy.</li>
  <li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0065327608603391">Lowdin’s 1970 paper</a> on orthonormalization and removing linear dependencies in basis sets is solid.</li>
  <li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.560070407">This 1973 Saunders paper</a> describes “level shifting,” which is ubiquitous today.</li>
</ul>

<h3>3.3 Density Fitting/Resolution of the Identity</h3>
<p>Density-fitting/resolution-of-the-identity (“RI”) approaches are becoming <em>de rigueur</em> for most applications. <a href="https://www.sciencedirect.com/science/article/abs/pii/000926149500621A">This 1995 Ahlrichs paper</a> explains “RI-J”, or density fitting used to construct the J matrix (<a href="https://www.sciencedirect.com/science/article/abs/pii/0009261493891517">this 1993 paper</a> is also highly relevant.) <a href="https://pubs.rsc.org/en/content/articlelanding/2002/cp/b204199p">This 2002 Weigend paper</a> extends RI-based methods to K-matrix construction. <a href="http://vergil.chemistry.gatech.edu/notes/df.pdf">Sherrill’s notes</a> are useful here, as is <a href="https://github.com/psi4/psi4numpy/blob/master/Tutorials/03_Hartree-Fock/density-fitting.ipynb">the Psi4Numpy tutorial</a>.</p>
<p>RI methods require the use of auxiliary basis sets, which can be cumbersome to deal with. <a href="https://pubs.acs.org/doi/10.1021/acs.jctc.6b01041">This 2016 paper</a> describes automatic auxiliary basis set generation, and <a href="https://pubs.acs.org/doi/10.1021/acs.jctc.3c00670">this 2023 paper</a> proposes some improvements. <a href="https://molssi-bse.github.io/basis_set_exchange/developer_api.html#basis_set_exchange.manip.autoaux_basis">There’s now a way</a> to automatically create auxiliary basis sets through the Basis Set Exchange API.</p>

<h3>3.4 Mechanics of Density-Functional Theory</h3>
<p>For Hartree–Fock theory, there are a lot of nice example programs (linked above); for density-functional theory, there are fewer examples. Here are a few resources which I found to be useful:</p>
<ul>
  <li><a href="https://pubs.aip.org/jcp/article/88/4/2547/91134/A-multicenter-numerical-integration-scheme-for">This 1988 paper</a>, from Becke, basically describes how all DFT quadrature is done today. I find <a href="https://www.sciencedirect.com/science/article/abs/pii/0009261496006008">this 1996 Stratmann paper</a> to be much more readable, though (plus it’s a linear-scaling method).</li>
  <li><a href="https://pubs.aip.org/aip/jcp/article-abstract/98/7/5612/843250/The-performance-of-a-family-of-density-functional?redirectedFrom=fulltext">This 1993 paper</a> by Gill and Head-Gordon discusses how to get analytical DFT gradients (among other things). Here's the key equation:

  <figure>
    <img class=centered-img src="../img/20250604_dft_grad.png" style="width:400px;" />
  </figure>

    This is the clearest exposition of the math behind DFT that I’ve read, although it doesn’t cover meta-GGA functionals or range-separated hybrids. (There’s a <a href="https://github.com/psi4/psi4numpy/blob/master/Tutorials/04_Density_Functional_Theory/4c_GGA_and_Meta_GGA.ipynb">Psi4Numpy explanation</a> of the math behind meta-GGA functionals, if you can parse the insane Psi4 syntax.)</li>
  <li><a href="https://www.sciencedirect.com/science/article/abs/pii/0009261494001995">This 1994 paper</a> discusses how to make DFT calculations with numerical quadrature rotationally invariant, which <a href="https://chemrxiv.org/engage/chemrxiv/article-details/60c74474ee301c02d6c7916e">many programs still haven’t figured out</a>…</li>
  <li><a href="https://pubs.aip.org/aip/jcp/article-abstract/101/10/8894/472028/The-effect-of-grid-quality-and-weight-derivatives?redirectedFrom=fulltext">This other 1994 paper</a> argues that it’s not necessary to add grid weight derivatives with large grids. People still argue about this one.</li>
  <li>The first paper describing range-separated hybrids, as far as I can tell, is <a href=https://pubs.aip.org/aip/jcp/article-abstract/118/18/8207/460359/Hybrid-functionals-based-on-a-screened-Coulomb?redirectedFrom=fulltext>this 2003 work</a> from Scuseria and co-workers.</li>
</ul>

<h3>3.5 Linear Scaling</h3>
<p>For large systems, it’s possible to find pretty large speedups and reach a linear-scaling regime for DFT (excepting operations like matrix diagonalization, which are usually pretty fast anyway). <a href="https://www.sciencedirect.com/science/article/abs/pii/0009261494011281">This 1994 paper</a> discusses extending the fast multipole method to Gaussian distributions, and how this can lead to linear-scaling <em>J</em>-matrix construction, and <a href="https://www.science.org/doi/10.1126/science.271.5245.51">this 1996 paper</a> discusses a similar approach. <a href="https://pubs.aip.org/aip/jcp/article-abstract/105/19/8969/479837/A-linear-scaling-method-for-Hartree-Fock-exchange?redirectedFrom=fulltext">This other 1996 paper</a> describes a related near-linear-scaling approach for <em>K</em> matrices. There are a bunch more papers on various approaches to linear scaling (Barnes–Hut, CFMM, GvfMM, Turbomole’s RI/CFMM, etc), but I think there are diminishing marginal returns in reading all of them.</p>

<h3>3.6 Geometry Optimization</h3>
<p>Geometry optimization for molecular systems is pretty complicated. Here’s a sampling of different papers, with the caveat that this doesn’t come close to covering everything:</p>
<ul>
  <li><a href="https://schlegelgroup.wayne.edu/Pub_folder/50.pdf">This 1981 Schlegel paper</a> explores the general considerations in optimizing molecules with quantum chemical methods.</li>
  <li><a href="https://link.springer.com/article/10.1007/BF00554788">This 1984 Schlegel paper</a> discusses the importance of initial Hessians in geometry optimization.</li>
  <li><a href="https://schlegelgroup.wayne.edu/Pub_folder/180.pdf">This 1996 Schlegel/Frisch paper</a> discusses use of internal coordinates for geometry optimizations, which is standard today, and <a href="https://schlegelgroup.wayne.edu/Pub_folder/390.pdf">this 2016 paper</a> explores some enhancements.</li>
  <li><a href="https://pubs.acs.org/doi/10.1021/ct050275a">This 2006 paper</a> extends the DIIS scheme to geometry optimization; this still seems underrated today.</li>
  <li><a href="https://pubs.aip.org/aip/jcp/article-abstract/140/16/164115/841317/A-finite-difference-Davidson-procedure-to-sidestep?redirectedFrom=PDF">This 2014 paper</a> discusses a way to obtain the lowest eigenvalues of the Hessian without computing the full matrix, thus accelerating TS searches.</li>
  <li><a href="https://chemrxiv.org/engage/chemrxiv/article-details/64e37e3700bbebf0e68dd9c4">This 2023 paper</a> benchmarks existing optimization algorithms, albeit for somewhat boring molecules.</li>
</ul>

<h3>3.7 Frequency + Thermochemistry</h3>
<p>I think the best guides here are <a href="https://gaussian.com/vib/">the Gaussian vibrational analysis white paper</a> and <a href="https://gaussian.com/vib/">the Gaussian thermochemistry white paper</a>—they basically walk through everything that’s needed to understand and implement these topics. It’s now pretty well-known that small vibrational frequencies can lead to thermochemistry errors; <a href="https://rowansci.com/blog/dft-errors">Rowan has a blog post</a> that discusses this and similar errors.</p>

<h3>3.8 Solvent</h3>
<p>Implicit solvent models, while flawed, are still essential for a lot of applications. <a href="https://pubs.rsc.org/en/content/articlelanding/1993/p2/p29930000799">This 1993 paper</a> describes the COSMO solvation method, upon which most modern implicit solvent methods are built. <a href="https://pubs.acs.org/doi/10.1021/jp992097l">Karplus and York found a better way to formulate these methods in 1999</a>, which makes the potential-energy surface much less jagged: </p>

<figure>
  <img class=centered-img src="../img/20250604_solvent.png" style="width:500px;" />
</figure>

<p>While there are many more papers that one could read in this field, these are the two that I found to be most insightful.</p>

<h3>3.9 Basis Sets Miscellania</h3>
<p>I haven’t talked much about basis sets specifically, since most basis-set considerations are interwoven with the ERI discussion above. But a few topics warrant special mention:</p>
<ul>
  <li><a href="https://www.sciencedirect.com/science/article/abs/pii/0009261496009177">This 1996 paper by Davidson</a> discusses how to convert general contraction into segmented contraction, which is important since the latter is much easier to handle.</li>
  <li>The issue of converting between spherical and Cartesian basis sets is tackled by <a href="https://onlinelibrary.wiley.com/doi/10.1002/qua.560540202">this 1995 work from Schelgel and Frisch</a>.</li>
</ul>




<h2>4. Conclusions</h2>
<p>There are hundreds of other papers which could be cited on these topics, to say nothing of the myriad topics I haven’t even mentioned here, but I think there’s diminishing marginal utility in additional links. The knowledge contained in the above papers, plus ancillary other resources, were enough to let me write my own quantum-chemistry code. Over the course of learning all this content, I wrote four different QM programs, the last of which, “Kestrel,” ended up powering Rowan for the first few months after we launched.</p>
<p>These programs are no longer directly relevant to anything we do at Rowan. We retired Kestrel last summer, and now exclusively use external quantum-chemistry software to power our users’ calculations (although I’ve retained some strong opinions; we explicitly override Psi4’s defaults to use the Stratmann–Scuseria–Frisch quadrature scheme, for instance).</p>
<p>But the years I spent working on this project were, I think, an important component of my scientific journey. Rene Girard says that <a href="https://corinwagen.github.io/public/blog/20230228_gilliam_and_girard.html">true innovation requires a “mastery” of the past’s achievements</a>. While I’m far from mastering quantum chemistry, I think that I’d be ill-suited to understand the impact of recent advances in neural network potentials without having immersed myself in DFT and conventional physics-based simulation for a few years.</p>
<p>And, on a more personal note, learning all this material was deeply intellectually satisfying and a fantastic use of a few years. I hope this post conveys some of that joy and can be helpful for anyone who wants to embark on a similar adventure. If this guide helped you and you have thoughts on how I could make this better, please feel free to reach out!</p>
<p><em>Thanks to Peter Gill, Todd Martínez, Jonathon Vandezande, Troy Van Voorhis, Joonho Lee, and Ari Wagen for helpful discussions.</em></p>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20250527_latitude.html'>How Does o3 Guess Latitude From Photos?</a></h2><i>May 27, 2025</i>
<p>
  Recently, <a href=https://x.com/KelseyTuoc/status/1917340813715202540>Kelsey Piper</a> shared that o3 (at time of writing, one of the latest reasoning models from OpenAI) could guess where outdoor images were taken with almost perfect accuracy. <a href=https://www.astralcodexten.com/p/testing-ais-geoguessr-genius>Scott Alexander</a> and others have since verified this claim. 
</p>

<p>
I’ve been playing around with this too: with the prompt linked in Scott’s post, o3 can guess where my photos were taken almost every time, even when I intentionally avoid anything that looks like it might be too helpful. After inspecting the reasoning, I was surprised to learn that o3 can almost always estimate the latitude to within a few degrees, which vastly restricts the range of potential answers.
</p>


<p>
I didn’t think this was possible before doing the research for this post. Here’s three recent examples—see if you can estimate the latitude yourself. (You may want to open the images in a new tab to zoom in.)
</p>


<figure>
  <img class=centered-img src="../img/20250527_ohio.png" style="width:500px;" />
</figure>

<figure>
  <img class=centered-img src="../img/20250527_mexico.png" style="width:550px;" />
</figure>

<figure>
  <img class=centered-img src="../img/20250527_argentina.png" style="width:550px;" />
</figure>

<p>
o3 guessed that these were 40–45º N,  25–28 ºN, and 34–36º S; in every case the answer was within that range. (I make sure to only give o3 screenshots, so it can’t access EXIF data or otherwise cheat at this assessment.) 
</p>

<p>
How is this possible? Here’s my best understanding of what o3 is doing, informed by a bunch of back-and-forth conversations with a friendly neighborhood AI model. (I’ll be assuming that the photo also has compass information, in keeping with standard GeoGuessr rules.)
</p>

<h2>Local Noon, On The Equinox</h2>
<p>
Let’s make this as simple as possible to start. On the spring equinox, at noon, at the equator, the sun is directly overhead. As a result, tall objects without any overhang won’t cast any shadows. 
</p>

<p>
If you’re not on the equator, then objects will still cast a shadow, and the length of the shadow S relative to the object’s height H tells you what latitude you’re at. Formally, we can define the solar elevation θ := arctan(H/S), and approximate the latitude φ as 90º − θ. 
</p>

<p>
I don’t do much mental trigonometry these days, but it’s pretty easy to make a table with some key values: 
</p>

<table>
  <thead>
    <tr>
      <th>S/H</th>
      <th>θ (Solar Elevation)</th>
      <th>φ (Latitude)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2:1</td>
      <td>26º</td>
      <td>64º</td>
    </tr>
    <tr>
      <td>1.3:1</td>
      <td>37º</td>
      <td>53º</td>
    </tr>
    <tr>
      <td>1:1</td>
      <td>45º</td>
      <td>45º</td>
    </tr>
    <tr>
      <td>0.7:1</td>
      <td>55º</td>
      <td>35º</td>
    </tr>
    <tr>
      <td>0.5:1</td>
      <td>63º</td>
      <td>27º</td>
    </tr>
    <tr>
      <td>0 (no shadow)</td>
      <td>90º</td>
      <td>0º</td>
    </tr>
  </tbody>
</table>


<p>
With a compass, figuring out which hemisphere you’re in is easy. In the northern hemisphere, the sun is south of you, so the shadows point north; in the southern hemisphere, the shadows point south.
</p>

<h2>Local Noon, Any Season</h2>
<p>
Unfortunately, it’s more complex than this—we’re not always on the equinox, meaning that we also have to account for solar declination (δ). The solar declination reflects how far away from the equator the sun is on any given date; δ is +23.4º on the summer solstice and -23.4º on the winter solstice. We have to adjust the above formula to take this into account: now φ ≈ 90º − θ + δ. 
</p>

<p>
Qualitatively, this means that shadows are shorter in summer than winter. A H/S ratio of 1:1 implies a latitude of 22º in winter or a latitude of 68º in summer, which is the difference between Cuba and Iceland. In practice, though, o3 can often figure out the season from how the trees look and how people are dressed.
</p>

<h2>Any Time, Any Season</h2>
<p>
When we move away from noon, things get a bit more complicated. We have to employ h, the hour angle, which is equal to 0º at local noon (when the sun is directly overhead) and increments by 15º every hour. Here’s the full equation:
</p>

<p>
sin(θ) = sin(φ)*sin(δ) + cos(φ)*cos(δ)*cos(h)
</p>

<p>
(o3 says “It’s just the spherical-law-of-cosines applied to the right-angled triangle on the celestial sphere.” Trivial! If you’re curious how we go from this to the simplified noon equation above, see Appendix A.)
</p>

<p>
This is a bit too involved for a GeoGuessr game—even o3 solves this in a Python environment. Qualitatively, though, this means that as we move away from noon and cos(h) becomes smaller, the solar elevation θ shrinks. Within an hour or two of noon, we’re only off by 1–2º, but after three hours we’re overestimating the latitude by 7–10º.
</p>

<p>
This seems bad, but with a compass it’s relatively easy to check how far from noon it is. Shadows point exactly north–south at local noon, and point increasingly east or west as the hour angle increases, so looking at the shadow orientation can tell you how much to update the latitude. In practice o3 recommends just ignoring shadow-related math after 3:00 PM or before 9:00 AM, since the error becomes too high. 
</p>

<h2>Putting It All Together</h2>
<p>
Here’s another recent GeoGuessr picture. Can we solve this now? 
</p>

<figure>
  <img class=centered-img src="../img/20250527_cambodia.png" style="width:550px;" />
</figure>


<p>
Here’s my attempt to apply what we’ve learned: we’re looking east and we can see that shadows are pointing north, so the sun is south. This means that we’re in the northern hemisphere. The shadow–height ratio is a bit tough to estimate from this picture; based on the Prius, maybe 0.5:1. So that gives us an equinox latitude of 27º N, minus say 5º for time of day (since the shadows seem angled), which leaves us with a latitude of… 22º N ± 23º depending on the season. Not terribly helpful.
</p>

<p>
I gave o3 the same image, and it told me the latitude was 12–15º N. The correct answer is 11.5 ºN (Phnom Penh). 
</p>

<p>
What did we do wrong? I asked o3 what went wrong with my reasoning, and this is what it told me (lightly edited for clarity): 
</p>
<ul>
  <li>
    <b>Wrong S:H ratio.</b> “A Toyota Hilux / Prius roof is ≈ 1.5–1.6 m. Measuring the dark patch on the tarmac (allowing for perspective) the shadow is 0.6–0.7 m, giving height : shadow ≈ 2.3–2.5.”
  </li>
  <li>
    <b>Wrong hour correction.</b> “How far the Sun drops below its noon altitude depends on the hour angle… Two hours before/after noon (h ≈ 30 °) knocks 10–15° off the altitude in the low latitudes, not 5°.”
  </li>
  <li>
    <b>Very wrong season correction.</b> “Season changes δ by ±23.4 °, but the corresponding change in the Sun’s altitude is modulated by both time-of-day (cos h) and your own latitude (cos φ). Thus the swing is never a flat ±23 ° except at noon on/near the tropics… 
Solve sin(67º) = sin(ϕ)*sin(δ) + cos(ϕ)*cos(δ)*cos(30º) for the full seasonal range. That inversion pins ϕ between 11° N (June solstice) and 16° N (December solstice), with the equinox coming out at ≈ 13° N.”
  </li>
</ul>

<p>
The last point deserves further discussion. The impact of solar declination on solar elevation is modulated both by the latitude and the hour angle—the 23.4º swing is scaled by cos(h) and by the actual latitude. With some Python code (Appendix B), we can quickly confirm that the effect is smaller at near-equatorial latitudes: 
</p>

<figure>
  <img class=centered-img src="../img/20250527_theta_by_phi.png" style="width:550px;" />
</figure>

<p>
Overall, though, there’s nothing here we haven’t already discussed; o3 just understands this material better than me and can do the math properly.
</p>

<h2>Conclusions</h2>
<p>
This is a fun activity for building AI-related intuition. o3 is very good at this and is able to do something that appears superhuman. Upon close inspection, the reasoning is legible, but I’m not really able to follow the same methods myself with any degree of precision; I’m just not quite able to do any step with sufficient accuracy. I’m hoping that I’ll be able to build up my skills over time—this would be a pretty fun party trick. 
</p>

<h2>Appendix A: Getting The Simplified Equation For Noon</h2>
<p>
The full equation is: 
</p>
<p>
sin(θ) = sin(φ)*sin(δ) + cos(φ)*cos(δ)*cos(h)
</p>
<p>
If we assume that we’re at local noon, cos(h) = 1. This lets us apply the following identity:
</p>
<p>
cos(α−β) = cos(α)*cos(β) + sin(α)*sin(β)
</p>
<p>
To get: 
</p>
<p>
sin(θ) = cos(φ - δ)
</p>
<p>
sin(θ) = sin(90º - φ + δ)
</p>
<p>
θ = 90º - φ + δ
</p>
<p>
Which is the simplified equation I presented above.
</p>

<h2>Appendix B: </h2>

<p>
  Here's the Python code to generate the above plot.
</p>

<pre class=code-block>
import numpy as np
import matplotlib.pyplot as plt

%matplotlib inline
%config InlineBackend.figure_format = 'retina'

def solar_elevation_vs_month(hour_local: float, latitude_deg: float) -> np.ndarray:
    """
    Return an array of solar-elevation angles (degrees) for each day at a given true-solar hour and latitude.
    """
    lat = np.deg2rad(latitude_deg)
    doy = np.arange(365)

    # Approximate solar-declination model (±23.44° sine fit)
    delta = np.arcsin(np.sin(np.deg2rad(23.44)) * np.sin(2 * np.pi / 365 * (doy - 80)))

    # Hour angle: 0° at solar noon; +15° per hour in the afternoon
    H = np.deg2rad((hour_local - 12.0) * 15.0)

    # Solar-elevation formula
    h = np.arcsin(np.sin(lat) * np.sin(delta) + np.cos(lat) * np.cos(delta) * np.cos(H))
    return np.rad2deg(h)


if __name__ == "__main__":
    plt.figure(figsize=(6, 4))

    months = np.array([15, 46, 75, 105, 135, 162,  198, 228, 258, 288, 318, 344])

    for h, l in [(15, 0), (15, 15), (15, 30), (15, 45), (15,60)]:
        elevations = solar_elevation_vs_month(h, l)
        plt.plot(np.arange(365), elevations, label=f"{h:.1f} h, {l:.1f}° N")
    
    plt.xticks(months, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
    plt.ylabel(f"Solar elevation (°)")
    plt.xlim(0,365)
    plt.ylim(0,60)
    plt.legend()
    plt.tight_layout()
    plt.show()
</pre>


</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20250517_hurry.html'>The Ruthless Elimination of Mottes</a></h2><i>May 17, 2025</i>
<br>
<figure>
  <img class=centered-img src="../img/20250517_icon.jpg" style="width:400px;" />
  <figcaption> A traditional iconographic depiction of Abraham's visitors. </figcaption>
</figure>
<br>

<p>I did not enjoy John Mark Comer’s book <em>The Ruthless Elimination of Hurry</em>.</p>

<p>Comer’s book is written to people trying to find meaning in a world that feels rushed, distracted, and isolated. At the time of writing, Comer was a Protestant pastor in Portland, Oregon, but he’s since stepped back to focus on creating resources for spiritual formation (like this book).</p>

<p>The book takes its title from a quote by Christian philosopher Dallas Willard:</p>

<blockquote>
    <p>Hurry is the great enemy of spiritual life in our day. You must ruthlessly eliminate hurry from your life.</p>
</blockquote>

<p>In the book, Comer argues that hurry is incompatible with love (p.&nbsp;23), patience (p.&nbsp;23), joy (p.&nbsp;25), peace (p.&nbsp;25), wisdom (p.&nbsp;52), and gratitude (p.&nbsp;52). Hurry is a sign that we aren’t accepting our God-given limitations (p.&nbsp;65), and hurrying causes irritability, restlessness, distraction, and isolation (pp.&nbsp;27,&nbsp;58,&nbsp;89).</p>

<p>The base state of man before the modern era, Comer argues, was unhurried (pp.&nbsp;42–45). God rests in Genesis&nbsp;1, and Jesus himself never hurried. The cure to our modern malaise, thus, is to embrace a life marked by slowness, solitude, simplicity, prayer, and rest. Comer advocates taking a literal 24-hour sabbath, rejecting consumerism, and trying to find a “perpetual Zen-like state of Jesus-derived joy and peace” (p.&nbsp;251).</p>

<p>Much of what Comer says is good. But the central argument of his piece, that hurrying should be eliminated, doesn’t seem defensible to me. Comer makes very few direct arguments that hurrying itself is bad, instead using hurrying as a metonym for a vaguely defined bucket of negative modern traits: isolation, anxiety, fear, and so on.</p>

<p>This is a classic example of a motte-and-bailey argument, popularized by Scott Alexander on <em>Slate Star Codex</em>. In his post <a href="https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/">“All In All, Another Brick In The Motte,”</a> he defines a motte-and-bailey argument thusly:</p>

<blockquote>
    <p>So the motte-and-bailey doctrine is when you make a bold, controversial statement. Then when somebody challenges you, you retreat to an obvious, uncontroversial statement, and say that was what you meant all along, so you’re clearly right and they’re silly for challenging you. Then when the argument is over you go back to making the bold, controversial statement.</p>
</blockquote>

<p>Comer does exactly this. “You must ruthlessly eliminate hurrying” is a bold, controversial statement—but the statement he actually defends is more like “anxiety and isolation are bad,” which doesn’t have quite the same transformative implications for modern Christian living.</p>

<p>I’ll go a step further and try to defend the assertion that hurrying can be good, actually. Here’s Genesis&nbsp;18:1–8&nbsp;(ESV), when Abraham receives God at Mamre (emphasis added):</p>

<blockquote>
    <p>And the Lord appeared to Abraham by the oaks of Mamre, as he sat at the door of his tent in the heat of the day. He lifted up his eyes and looked, and behold, three men were standing in front of him. When he saw them, <strong>he ran from the tent door to meet them</strong> and bowed himself to the earth and said, “O Lord, if I have found favor in your sight, do not pass by your servant. Let a little water be brought, and wash your feet, and rest yourselves under the tree, while I bring a morsel of bread, that you may refresh yourselves, and after that you may pass on—since you have come to your servant.” So they said, “Do as you have said.” <strong>And Abraham went quickly into the tent</strong> to Sarah and said, “<strong>Quick</strong>! Three seahs of fine flour! Knead it, and make cakes.” <strong>And Abraham ran to the herd</strong> and took a calf, tender and good, and gave it to a young man, <strong>who prepared it quickly.</strong> Then he took curds and milk and the calf that he had prepared, and set it before them. And he stood by them under the tree while they ate.</p>
</blockquote>

<p>In the above passage, Abraham hurries and tells others to hurry. I think it’s pretty clear from context that Abraham’s behavior here is correct hospitality, not sinful, since God immediately blesses Abraham (v.&nbsp;10) and says he’s been chosen ”to keep the way of the Lord by doing righteousness and justice” (v.&nbsp;19).</p>

<p>Here’s a few other passages defending the practice of hurrying, which I will summarize for brevity’s sake:</p>

<ul>
    <li>Lot is commanded by angels to flee in a hurry from Sodom (Genesis&nbsp;19).</li>
    <li>In Exodus&nbsp;12, the Passover meal is to be eaten in haste.</li>
    <li>After Ziklag is raided and taken captive by the Amalekites, David and his soldiers pursue them until a third of his army is too tired to continue (1&nbsp;Samuel&nbsp;30).</li>
    <li>In 2&nbsp;Kings&nbsp;4, Elisha commands his servant Gehazi to “run at once” to meet the Shunammite woman.</li>
    <li>After Mary receives the revelation from Gabriel, she “went with haste” to Elizabeth (Luke&nbsp;1:39).</li>
    <li>In Luke&nbsp;15, the father of the prodigal son runs out of the house, and then commands his servants to “bring quickly” the best robe.</li>
    <li>In Acts&nbsp;8, Philip runs to the Ethiopian eunuch in his chariot, following the direction of the Holy Spirit.</li>
    <li>In 2&nbsp;Timothy, Paul twice urges Timothy to come and join him “soon” and “before winter” (vv.&nbsp;9,&nbsp;21).</li>
</ul>

<p>These points may seem obvious—clearly, if Amalekite raiders carried off your family, you would hurry after them! But even a trivial example like this demonstrates that hurrying is not intrinsically opposed to the will of God.</p>

<p>Comer also argues that Jesus himself never hurried (p.&nbsp;92). This is debatable—Mark uses the word “immediately” to describe many of Jesus’s actions, but that may reflect a Markean narrative style more than the actual pace of actions. Jesus himself commands Zaccheus to hurry (Luke&nbsp;19:5), and his anger cleansing the temple and agony at Gethsemane should be sufficient to dispel the idea that Jesus perpetually existed in a “Zen-like” (p.&nbsp;251) stoic state. Stress is not incompatible with sanctification.</p>

<p>Comer further argues that we’re called to walk with God, not run with him (p.&nbsp;23). This is quite literally false! In 1&nbsp;Corinthians&nbsp;9:25–27, Paul uses the metaphor of running to convey the discipline, self-control, and perseverance required for mature Christian living:</p>

<blockquote>
    <p>Do you not know that in a race all the runners run, but only one receives the prize? So run that you may obtain it. Every athlete exercises self-control in all things. They do it to receive a perishable wreath, but we an imperishable. So I do not run aimlessly; I do not box as one beating the air. But I discipline my body and keep it under control, lest after preaching to others I myself should be disqualified.</p>
</blockquote>

<p>Equating maturity with a restful, non-stressed life sets Christians up for disappointment. Hebrews&nbsp;11 specifically highlights the heroes “of whom the world was not worthy” who “went about in skins of sheep and goats, destitute, afflicted, mistreated” (vv.&nbsp;37–38). A stressful life doesn’t mean, as Comer argues, that “something is out of whack” (p.&nbsp;85). God’s rest will come, but it might not come today.</p>

<p>The conclusion here is not that we should hurry more. Most people hurry for bad reasons, stuck chasing selfish desires or climbing social ladders in pursuit of an elusive fulfillment. But the call of Christianity is not to abnegate these bad desires but to align them with God’s will. As Rene Girard says in <em>I Saw Satan Fall Like Lightning</em> (p.&nbsp;13, emphasis original):</p>

<blockquote>
    <p>What Jesus invites us to imitate is his own <em>desire</em>, the spirit that directs towards the goal on which his intention is fixed: to resemble God the Father as much as possible.</p>
</blockquote>

<p>What we are willing to hurry for reflects what we care about. We see this reflected in the passages above: Abraham hurries to show hospitality and welcome God into his life, David hurries to save the captives, and Mary&nbsp;&amp;&nbsp;Philip hurry to share the good news of the gospel. We should care enough about these things that we’re willing to hurry for them.</p>

<p>Comer’s call to a life of virtue, peace, and rest is excellent—and at the margin, he’s probably right that most people should hurry less in their lives. But the central claim of the book is just not correct. The vision of Christian maturity contained in <em>The Ruthless Elimination of Hurry</em> seems a little too close to California-style Zen Buddhism and other modern mystical practices to fully align with Scripture, and I think this is bad.</p>

<p><em>Thanks to Taylor Wagen, Tony Robinson, Elias Mann, Jonathon Vandezande, and Chloe Wagen for helpful discussions, and for Ari Wagen for originally pointing me to read Girard.</em></p>

</div><div class='next-link'><a href='blog_p2.html'>next page</a></div><br>
  </body>
  <br>
  <footer>
    <a href="mailto:corin.wagen+blog@gmail.com">email</a>
    <a href="https://github.com/corinwagen">github</a>
    <a href="https://twitter.com/CorinWagen">x</a>
    <a href="https://scholar.google.com/citations?user=SW0Uhs0AAAAJ">google scholar</a>
    <div style="float:right;">
      <a href="/rss.xml">rss</a>
      <a href="https://cwagen.substack.com">substack</a>
    </div>
  </footer>
</html>
