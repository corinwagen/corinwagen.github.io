<!DOCTYPE html>
<html>
  <head>
    <title>
      Blog
    </title>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta name="language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="../../static/style.css">

    <link rel="alternate" type="application/rss+xml" title="RSS feed for the blog" href="/rss.xml">

    <!--google-->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MTNZ0ZSG3W"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-MTNZ0ZSG3W');
    </script>

  </head>
  <body>
    <ul class="menu-list">
      <li class="menu-item"><a href="index.html" class="menu-link menu-title">Corin Wagen</a></li>
      <li class="menu-item"><a href="index.html#about" class="menu-link">About</a></li>
      <!--<li class="menu-item"><a href="index.html#projects" class="menu-link">Projects</a></li>-->
      <!--<li class="menu-item"><a href="index.html#past_work" class="menu-link">Past Work</a></li>-->
      <li class="menu-item"><a href="index.html#pubs" class="menu-link">Papers</a></li>
      <li class="menu-item">
        <a href="blog_p1.html" class="menu-link">Blog</a>
        <a href='archive.html' class="menu-link">(Archive)</a>
      </li>
    </ul>
    <h1 class='blogroll-header'>Blog</h1><div class='previous-link'><a href='blog_p4.html'>previous page</a></div><div class='next-link'><a href='blog_p6.html'>next page</a></div><br><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20240613_simple_md.html'>Running Simple MD Simulations</a></h2><i>June 13, 2024</i>
<p>
Scientific software can be confusing, particularly when you're doing something that the software isn't primarily intended for. 
I often find myself wanting to run quick-and-dirty molecular dynamics simulations on small organic molecules, but I've struggled to find an easy way to do this using open-source tools like OpenMM. 
</p>

<p>
This is particularly frustrating since I feel like I should be equipped to succeed at this task: 
</p>

<ul>
<li>I know how to code (well enough for a scientist).</li>
<li>I've read <a href=https://www.amazon.com/Understanding-Molecular-Simulation-Applications-Computational/dp/0122673514>a textbook on MD</a> cover-to-cover.</li>
<li>I've even written <a href=https://github.com/corinwagen/presto>my own MD package</a> from scratch.</li>
</ul>

<p>
Yet despite all this, I've probably tried and failed to use OpenMM for my research a half-dozen times over the past five years (<a href=https://github.com/openmm/openmm/issues/2937>evidence</a>). I always get bogged down somewhere: I don't have PDB files for my compounds, or I can't figure out how to get the forcefield parameters right for a small molecule, or I just get lost in a sea of similar-sounding classes and objects. Part of the problem here is that all the "intro to MD" tutorials seem to assume that you're hoping to run an MD simulation on a protein from the PDB—so if you have an .xyz file, it's not obvious how to proceed.
</p>

<p> Nevertheless, I've finally succeeded. Here's the code, with minor annotations interspersed:</p>

<pre class=code-block>
from openff.toolkit import Molecule, Topology

from openmm import *
from openmm.app import *

import nglview
import mdtraj
import matplotlib.pyplot as plt
import numpy as np
import openmoltools
import tempfile
import cctk
import openmmtools
import math
from random import random, randint

from sys import stdout
import pandas as pd

from rdkit import Chem
from rdkit.Chem import AllChem

from openmmforcefields.generators import SMIRNOFFTemplateGenerator

%config InlineBackend.figure_format='retina'
</pre>

<p> 
Already, we're off to a complex start: we need OpenFF, OpenMM, <span class=code>openmoltools</span>, <span class=code>openmmtools</span>, and <span class=code>openmmforcefields</span>
(not to mention <span class=code>nglview</span> and <span class=code>mdtraj</span>). There's a broader point to be made here about the state of scientific software and how this relates to academic incentive structure, but I digress...
</p>

<pre class=code-block>
smiles = "c1cc(F)ccc1O"

def generate_forcefield(smiles: str) -&gt; ForceField:
    """ Creates an OpenMM ForceField object that knows how to handle a given SMILES string """
    molecule = Molecule.from_smiles(smiles)
    smirnoff = SMIRNOFFTemplateGenerator(molecules=molecule)
    forcefield = ForceField(
      'amber/protein.ff14SB.xml',
      'amber/tip3p_standard.xml',
      'amber/tip3p_HFE_multivalent.xml'
     )
    forcefield.registerTemplateGenerator(smirnoff.generator)
    return forcefield

def generate_initial_pdb(
    smiles: str,
    min_side_length: int = 25, # Å
    solvent_smiles = "O",
) -&gt; PDBFile:
    """ Creates a PDB file for a solvated molecule, starting from two SMILES strings. """

    # do some math to figure how big the box needs to be
    solute = cctk.Molecule.new_from_smiles(smiles)
    solute_volume = solute.volume(qhull=True)
    solvent = cctk.Molecule.new_from_smiles(solvent_smiles)
    solvent_volume = solvent.volume(qhull=False)

    total_volume = 50 * solute_volume # seems safe?
    min_allowed_volume = min_side_length ** 3
    total_volume = max(min_allowed_volume, total_volume)

    total_solvent_volume = total_volume - solute_volume
    n_solvent = int(total_solvent_volume // solvent_volume)
    box_size = total_volume ** (1/3)

    # build pdb
    with tempfile.TemporaryDirectory() as tempdir:
        solute_fname = f"{tempdir}/solute.pdb"
        solvent_fname = f"{tempdir}/solvent.pdb"
        system_fname = f"system.pdb"

        smiles_to_pdb(smiles, solute_fname)
        smiles_to_pdb(solvent_smiles, solvent_fname)
        traj_packmol = openmoltools.packmol.pack_box(
          [solute_fname, solvent_fname],
          [1, n_solvent],
          box_size=box_size
         )
        traj_packmol.save_pdb(system_fname)

        return PDBFile(system_fname)

def smiles_to_pdb(smiles: str, filename: str) -&gt; None:
    """ Turns a SMILES string into a PDB file (written to current working directory). """
    m = Chem.MolFromSmiles(smiles)
    mh = Chem.AddHs(m)
    AllChem.EmbedMolecule(mh)
    Chem.MolToPDBFile(mh, filename)

forcefield = generate_forcefield(smiles)
pdb = generate_initial_pdb(smiles, solvent_smiles="O")

system = forcefield.createSystem(
    pdb.topology,
    nonbondedMethod=PME,
    nonbondedCutoff=1*unit.nanometer,
)
</pre>

<p> This code turns a SMILES string representing our molecule into an OpenMM System, which is a core object in the OpenMM ecosystem. To do this, we have to do a lot of shenanigans involving figuring out how many solvent molecules to add, calling <a href=https://m3g.github.io/packmol/>PACKMOL</a>, etc. One of the key steps here is the <span class=code>SMIRNOFFTemplateGenerator</span> (documented <a href=https://github.com/openmm/openmmforcefields>here</a>), which uses one of the recent OpenFF forcefields to describe our chosen molecule.
</p>


<pre class=code-block>
# initialize Langevin integrator and minimize
integrator = LangevinIntegrator(300 * unit.kelvin, 1 / unit.picosecond, 1 * unit.femtoseconds)
simulation = Simulation(pdb.topology, system, integrator)
simulation.context.setPositions(pdb.positions)
simulation.minimizeEnergy()

# we'll make this an NPT simulation now
system.addForce(MonteCarloBarostat(1*unit.bar, 300*unit.kelvin))
simulation.context.reinitialize(preserveState=True)

checkpoint_interval = 100
printout_interval = 10000

# set the reporters collecting the MD output.
simulation.reporters = []
simulation.reporters.append(DCDReporter("traj_01.dcd", checkpoint_interval))
simulation.reporters.append(
    StateDataReporter(
        stdout,
        printout_interval,
        step=True,
        temperature=True,
        elapsedTime=True,
        volume=True,
        density=True
    )
)

simulation.reporters.append(
    StateDataReporter(
        "scalars_01.csv",
        checkpoint_interval,
        time=True,
        potentialEnergy=True,
        totalEnergy=True,
        temperature=True,
        volume=True,
        density=True,
    )
)

# actually run the MD
simulation.step(500000) # this is the number of steps, you may want fewer to test quickly
</pre>

<p>
Here, we configure the settings that will be familiar to people who read MD textbooks. I've chosen to use a Langevin integrator/thermostat to control temperature, and added a Monte Carlo barostat to make this an NPT simulation (constant pressure &amp; temperature). This isn't appropriate for all uses, but it means we don't have to worry about getting the box size exactly right. We also configure how we're going to save data from the simulation, and then the last line actually runs it (this might take a while if you don't have a GPU). 
<p>

<p> Once we've run this simulation, we can visualize the output and watch things wiggle around! The MDTraj trajectory is <a href=https://www.mdtraj.org/1.9.8.dev0/examples/index.html>a pretty versatile object</a> so you can do much more analysis here if you want to.</p>

<pre class=code-block>
# build MDTraj trajectory
t = mdtraj.load("traj_01.dcd", top="init_01.pdb")

# visualize the trajectory - this works in jupyter at least
view = nglview.show_mdtraj(t)
view.clear_representations()
view.add_licorice()
view.add_unitcell()
view
</pre>

<figure>
  <img class=centered-img src=../img/20240613_nglview.png style="width:550px;" />
  <figcaption>NGLView is actually pretty great, except if you're forming or breaking bonds.</figcaption>
</figure>

<p>It's also good to check that the thermostat actually worked and nothing blew up:</p>

<pre class=code-block>
# check that the thermostat is working
df = pd.read_csv("scalars_01.csv")
df.plot(kind="line", x='#"Time (ps)"', y="Temperature (K)")
</pre>

<p>This is probably laughably simple to an OpenMM expert, but it works well enough for me. Here's my current list of things I still don't know how to do: </p>

<ul>
<li>Start with a specific set of 3D coordinates, not just a SMILES string. This is my biggest issue: it's not easy to specify the geometry of a supramolecular complex using SMILES strings, and while I feel that I ought to be able to modify one of these objects and supply the coordinate information directly, I'm not sure exactly how. (Relatedly, I've never gotten the hang of PDB files for small molecules.)
<li>Fit specific torsions or interactions to high-level data—I see people do this in the literature, but I don't know how.</li>
<li>Frankly, run any more interesting sorts of simulations! Normal MD is way too slow for a lot of things, but enhanced sampling methods get complicated fast: I've done WHAM using my own software, but I don't really know how to do WHAM or metadynamics in other software packages.</li>
<li>Relatedly, I've never gotten the hang of <a href=https://www.plumed.org/>PLUMED</a>.</li>
<li>Build or validate models of non-aqueous solvents. Can I just use this workflow to study, e.g., liquid HF? And how do I figure out if I have the right dipole moment or boiling point for liquid HF? </li>
</ul>

<p>Still, I hope this script is a useful asset to the community, and helps other people not make the same mistakes I did.</p>

<i>Thanks to Dominic Rufa for answering some of my stupid questions.</i>
</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20240510_difflinker.html'>Generative Linker Design</a></h2><i>May 10, 2024</i>
<p>
<b>
  Update: As of October 2024, you can now run DiffLinker calculations through <a href=rowansci.com>Rowan</a>, my computational chemistry startup. Read more about this in <a href=https://rowansci.substack.com/p/difflinker-mmff94-and-common-dft>our newsletter</a>!
</b>
</p>

<p>
Much molecular design today can be boiled down to “put the right functional groups in exactly the right places.” In catalysis, proper positioning of functional groups to complement developing charge or engage in other stabilizing non-covalent interactions with the transition state can lead to vast rate accelerations. A classic demonstration of this is Uyeda and Jacobsen’s <a href=https://pubs.acs.org/doi/abs/10.1021/ja110842s>enantioselective Claisen rearrangement</a>, where a simple catalyst presents a guanidinium ion to stabilize an anionic region and an electron-rich arene to stabilize a cationic region. Together, these interactions lead to high enantioselectivity and a 250-fold rate increase over the background reaction.
</p>

<figure>
  <img class=centered-img src="../img/20240510_uyeda.png" style="width:500px;" />
  <figcaption>I freely admit this choice of example is biased, but this is a great paper. </figcaption>
</figure>

<p>
While putting the right functional groups in the right positions might sound easy, the underlying interactions are often exquisitely sensitive to distance, which makes finding the right molecular scaffold very challenging. Jeremy Knowles put this nicely in his <a href=https://www.nature.com/articles/350121a0>1991 perspective on enzyme catalysis</a>:
</p>

<blockquote>
Although it is too early to generalize, it is evident that in this case <i>[triose phosphate isomerase]</i> at least, the positioning of functionality at the active site of the enzyme needs to be quite precise if full catalytic potency is to be realized… The good news for catalyst engineers is that proper placement of appropriate groups in the right environment seems to be enough. The not-so-good news is that this placement must be very precise.
</blockquote>

<p>
Proper positioning of various groups isn’t just a problem in catalysis—it’s also very important in drug design. Lots of topics in medicinal chemistry essentially boil down to a variant of the positioning problem: 
</p>

<ol>
<li>
Recent years have seen an explosion in the number of arene bioisosteres, i.e. “ways to connect two groups the same distance apart as an arene would without using any aromatic rings.” This is nice because you can use these bioisosteres to e.g. tune biophysical properties, like lipophilicity, solubility, and membrane permeability, while ideally not affecting the actual conformation of the molecule too much. Here’s a graphic from Chris Swain showing some options for replacing a 1,4-disubstituted arene:

<figure>
  <img class=centered-img src="https://www.cambridgemedchemconsulting.com/resources/bioisoteres/aromatic_bioisosteres_files/aromaticbicycloreps.png" style="width:400px;" />
  <figcaption>Taken from <a href=https://www.cambridgemedchemconsulting.com/resources/bioisoteres/aromatic_bioisosteres.html>this page</a>.</figcaption>
</figure>

(There's lots of work on this; see also the Baran Lab's <a href=https://baranlab.org/wp-content/uploads/2020/11/Bioisosteres-v2-Recent-Trends-and-Tactics.pdf>great overview of bioisosteres</a>.)

</li>
<li>


“Scaffold hopping” generally means switching the core of a molecule while preserving key interactions and substituents (<a href=https://www.cresset-group.com/about/news/what-does-scaffold-hopping-mean-to-you/>although the term is a little vague</a>). Scaffold hops often look for new structures that don’t suffer from the ADME/toxicity liabilities of the original structure, which necessitates finding a new core that positions substituents in the same way. Here's a nice example of a scaffold hop in a tyrosine kinase inhibitor, from a <a href=https://apps.dtic.mil/sti/tr/pdf/ADA572958.pdf>review</a> by Hongmao Sun and co-workers:

<figure>
  <img class=centered-img src="../img/20240510_tyk.png" style="width:550px;" />
  <figcaption>(This is Figure 8 in the reference.)</figcaption>
</figure>

</li>
<li>

Linker design has become incredibly important for PROTACs and other heterobifunctional molecules, as choosing a good linker is often key to drug efficacy (<a href=https://chemistry-europe.onlinelibrary.wiley.com/doi/abs/10.1002/cmdc.202200615>e.g.</a>). Unfortunately there are a vast variety of potential linkers, and it’s far from obvious to figure out which one will best balance, affinity, bioavailability, stability, and other properties:

<figure>
  <img class=centered-img src="../img/20240510_vhl.png" style="width:550px;" />
  <figcaption>Taken from <a href=https://www.sciencedirect.com/science/article/pii/S0968089623001827>this review</a>.</figcaption>
</figure>

</li>
<li>

One of the toughest parts of fragment-based drug design is finding the right way to connect fragments which bind to different parts of the desired pocket. Here’s what <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6930586/>Philine Kirsch and co-workers</a> have to say about this:

<blockquote>
Finding the right linker motif, which orients the individual fragment units in the favourable geometry in relation to each other without introducing too much flexibility whilst maintaining the binding poses of both fragments, can be very challenging. If successful, the combination of two fragments with rather low affinity could result in significantly higher affinity and has the potential to result in “superadditive” contributions of both binding motifs. The challenge in fragment linking is the exploration of the binding mode of both fragments and the identification of an optimal linker. Only in this case, the overall reduced so-called rigid body entropy translates into synergistically-improved affinity.
</blockquote>

</li>
</ol>

<p>
What’s hard about all these positioning problems is that finding a molecule that orients substituents in a given way is incredibly non-obvious: molecules are inherently discrete and atomic, making it hard to change a distance or angle by a precise percent. You can have two carbon atoms between your substituents, or you can have three carbon atoms, but you can’t have 2.5 carbon atoms. This makes prospective design very challenging: I can model my protein’s active site and figure out that I want a an <i>ortho</i>-pyridyl substituent and a tetrazole 8 Å apart at a 30º angle, but working backwards to an actual scaffold almost always requires a lot of trial and error. 
</p>

<p>
A <a href=https://www.nature.com/articles/s42256-024-00815-9>recent paper</a> from Ilia Igashov and co-workers sets out to solve exactly this “inverse design” problem: given two substituents, can we use ML to find a linker that connects them in the desired orientation? Their solution is DiffLinker, a diffusion-based method that takes separate atomic fragments and generates a linker that connects them.
</p>

<figure>
  <img class=centered-img src="../img/20240510_difflinker.png" style="width:500px;" />
</figure>

<p>
There’s been other work in this area, but the DiffLinker authors argue that their model stands out in a few ways. DiffLinker generally produces more synthetically accessible and drug-like molecules than competitor methods, although the relative ranking of models does change significantly from benchmark to benchmark. Also, they’re not limited to joining pairs of molecule structures: DiffLinker can perform “one-shot generation of the linker between any arbitrary number of fragments,” which lets them vastly outperform other models when linking three or more fragments. 
</p>

<p>
For cases where fragments must be joined in a protein pocket, the authors train a pocket-conditioned model, and show that this model results in many fewer clashes than an unconstrained model. They can use this model to recapitulate known drug structures, which they demonstrate with a known HSP90 inhibitor derived from molecular fragments. (It’s worth noting that the authors got the desired inhibitor structure only 3 times out of 1000 DiffLinker predictions.) They also show that their protein-conditioned model produces molecules that have good binding affinity as assessed by docking (GNINA/Vina), with the huge caveat that docking scores are notoriously inaccurate.
</p>

<figure>
  <img class=centered-img src="../img/20240510_hsp90.png" style="width:500px;" />
  <figcaption><b>a</b> is the experimental fragments, <b>b</b> is the input to DiffLinker, <b>c</b> is the experimental inhibitor, and <b>d</b> is the DiffLinker-generated inhibitor. Not bad!</figcaption>
</figure>

<p>
There’s still plenty of work that needs to be done here: for instance, the authors readily acknowledge that PROTACs are still too challenging:
</p>

<blockquote>
While DiffLinker effectively suggests diverse and valid chemical structures in tasks like fragment linking and scaffold hopping, we have observed that generating relevant linkers for PROTAC-like molecules poses a greater challenge. The main difference between these problems lies on the linker length and the distance between the input fragments. While the average linker size in our training sets is around 8 atoms (5 for ZINC, 10 for GEOM, 10 for Pockets), a typical linker in a PROTAC varies between 12 and 20 atoms. It means that the distribution of linkers in PROTACs has different characteristics compared to the distributions of linkers provided in our training sets. Therefore, to improve the performance of DiffLinker in PROTAC design, one may consider retraining the model using more suitable PROTAC data.
</blockquote>

<p>
DiffLinker is open-source and comes with pre-trained models, so I played around with it a bit myself to see how well it worked. I sketched out a classic <i>meta</i>-terphenyl scaffold, deleted the central phenyl ring, and then asked DiffLinker to connect the now-separated phenyl rings. I was hoping that DiffLinker would come up with one of <a href=https://enamine.net/building-blocks/medchem/saturated-bioisosteres-of-meta-substituted-benzene>Enamine’s cool suggestions</a> for <i>meta</i>-arene bioisosteres, but in all five cases I just got back some variant on a benzene ring… which isn’t surprising in hindsight. 
</p>

<figure>
  <img class=centered-img src="../img/20240510_rowan.png" style="width:400px;" />
  <figcaption>DiffLinker also doesn't output hydrogens, which is a little annoying.</figcaption>
</figure>

<p>
Although I don’t think this version of DiffLinker is going to replace humans at any of the tasks I talked about above, this still seems like a pretty cool direction for generative chemical ML. I’m excited to see future versions of methods like DiffLinker that are able to generate predictions conditioned on other molecular properties to allow for guided exploration of molecular space. (For instance, it would have been nice to request fragments that were three-dimensional above, so as to avoid getting boring benzenes back.)
</p>

<p>
I also suspect that DiffLinker, like other generative chemical models, will increase the demand for accurate physics-based methods for refining and validating the output predictions. DiffLinker’s grasp of potential energy surfaces is presumably worse than DFT or other dedicated ML potentials, and a hybrid workflow where DiffLinker generates structures and a higher-quality method optimizes and scores them will probably be much more accurate than just DiffLinker alone. Generative AI is having a moment right now, but for better or worse I think “classic” molecular simulation is here to stay too. 
</p>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20240425_pymsym.html'>Molecular Symmetry Analysis Made Easy</a></h2><i>April 25, 2024</i>
<p>
Pure mathematics has all sorts of unexpected connections to other fields, and chemistry is no exception. One example of this is group theory: while I never delved deeply enough into math to actually study group theory as its own field, I've had to learn how to assign <a href=https://en.wikipedia.org/wiki/Point_groups_in_three_dimensions>point groups</a> to three-dimensional objects for several inorganic chemistry classes. This process, demonstrated below for water, basically entails finding all of the possible symmetry operations for a given molecule:
</p>

<figure>
  <img class=centered-img src="../img/20240425_water_c2v.png" style="width:400px;" />
  <figcaption>Finding the point group of water.</figcaption>
</figure>

<p>
This might seem arcane but becomes quite important in several contexts. In computational chemistry, proper consideration of point groups and their corresponding symmetry numbers is needed to handle entropic effects correctly. Dan Singleton makes this point forcefully in his <a href=https://pubs.acs.org/doi/10.1021/ja5111392>2015 study of the Baylis–Hillman reaction</a> (SI pp. S24–S25):
</p>

<blockquote>
For an entropy calculation to be properly compared with experimental observations, it should allow for a
series of entropy effects that are not included in the entropies calculated from frequencies normally supplied
by electronic structure calculations. This includes allowance for symmetry numbers and the effects of
mixing of structures on entropy. The corrections are usually simple yet they are rarely done in computational
mechanistic studies. A rationalization of this is that the effects are small and often make no difference for
the results of greatest interest in papers. However, the effects can at times be quite large (see for example
Seal, P.; Papajak, E.; Truhlar, D. G. <i>J. Phys. Chem. Lett.</i> <b>2012</b>, <i>3</i>, 264-271). Judging by papers where the
consideration of symmetry numbers and entropy of mixing would make a difference but is ignored (for one 
example, see <i>J. Chin. Chem. Soc.</i> <b>2001</b>, <i>48</i>, 193-200), the ideas are not as widely recognized as needed.
</blockquote>

<p>
Why don't most people take symmetry into account? One reason is that while it's pretty easy to find the point group of a molecule by inspection, it's much harder to figure out how to do it programmatically. I ran into this issue writing code for Rowan, and was really pleased to find <a href=https://github.com/mcodev31/libmsym><i>libmsym</i></a>, a package that automatically finds the point group for a given molecule. (Here's <a href=https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0193-3>the paper</a> describing <i>libmsym</i>.) We've had great results using this library for Rowan's thermochemistry module.
</p>

<p>
Unfortunately, <i>libmsym</i> is now nine years old and we've also had problems with the code: in particular, I recently upgraded from an old Intel MacBook to a new M3 MacBook Pro, and there aren't any prebuild Apple Silicon-compatible wheels for <i>libmsym</i> on Pypi! Since this is an issue which <a href=https://github.com/mcodev31/libmsym/issues/26>other people</a> have also faced with <i>libmsym</i>, and neither the original author nor the listed maintainer have responded to my emails, I decided to just fork the repository and fix this issue myself.
</p>

<p>
It took a bit more work than I was expecting (I ended up completely restructuring the package, rewriting all the CMake files, and moving the Python build to <a href=https://scikit-build-core.readthedocs.io/en/latest/index.html>scikit-build-core</a>), but I'm happy to share the final product, <a href=https://github.com/corinwagen/pymsym><i>pymsym</i></a>. <i>pymsym</i> should be compatible with any modern Linux or Mac architecture (thanks to <a href=https://cibuildwheel.pypa.io/en/stable/options/>cibuildwheel</a>) and can be installed from Pypi. Simply run <span class=code>pip install pymsym</span>.
</p>

<p>
All the original <i>libmsym</i> code is there, and I've also added an additional high-level Python API for quickly predicting point groups and symmetry numbers:
</p>

<pre class=code-block>
import pymsym

# water
atomic_numbers = [8, 1, 1]
positions = [
  [0.007544053252786398, 0.39774343371391296, 0.0],
  [-0.7671031355857849, -0.18439316749572754, 0.0],
  [0.7595590949058533, -0.21335026621818542, 0.0]
 ]

print(pymsym.get_point_group(atomic_numbers, positions)) # C2v
print(pymsym.get_symmetry_number(atomic_numbers, positions) # 2
</pre>

<p>
I hope this is helpful to the community—let me know if you find any bugs!
</p>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20240325_solidworks.html'>The SolidWorks Model of Simulation</a></h2><i>March 25, 2024</i>
<p>
<i>Apologies for the long hiatus: we've had some health issues in the family, and startup life has been particularly overwhelming. With any luck, I'll be able to return to a more regular posting frequency soon.</i>
</p>

<p>
What’s the right relationship between theory, computation, and experiment? Much has been written on this. In this piece, I want to put forward an answer that I think is underrated in the life sciences—what I call the “SolidWorks model” of simulation. 
</p>

<p>
For the unfamiliar, SolidWorks is a program which allows engineers to design objects in the computer: the user can create a 3D model of their device, figure out the measurements that allow the parts to fit together in the desired way, and then go into the lab and actually build everything. (I’m not a SolidWorks power user, but I spent a semester messing around with it in high school and I’ve been thinking back on this recently.)
</p>


<figure>
  <img class="centered-img" src="../img/20240325_solidworks.jpg" style="width:550px;" alt="picture of SolidWorks" />
  <figcaption>A screenshot of SolidWorks.</figcaption>
</figure>

<p>
What are the distinctive features of SolidWorks? 
</p>

<ul>
<li>
<b>SolidWorks doesn’t predict overall success.</b> If you’re designing a new gearbox in SolidWorks, you can check that the parts will fit together, but you don’t know if it will run efficiently or not. Modeling is not supposed to replace actually building and testing the part.
</li>
<li>
<b>SolidWorks can be used by normal engineers, not dedicated computer experts.</b> It’s quick and easy to model things, so modeling becomes a part of the regular engineering/design workflow. You can model a part, make it, adjust the model, make it again, and so on and so forth. 
</li>
<li>
<b>SolidWorks assists human intuition instead of trying to replace it.</b> SolidWorks only draws what you tell it to, which means all the ideas still come from humans—to the extent that SolidWorks increases productivity, it does so by helping people understand what they’re working on more clearly. This comports with Richard Hamming’s idea that “the purpose of computing is insight, not numbers.”
</li>
</ul>

<p>
Astute readers will notice differences from how simulations in the life sciences are typically conducted. It’s rare in chemistry or biology to have computations and experiments performed in the same research group, let alone by the same person—but this is crucial to SolidWorks-style simulation, where experimental scientists must quickly gain insight from their computations. If someone from a different team has to get around to answering their request or a job takes overnight to run, the experimental scientist will move on and modeling will be excluded from the design/build/test cycle.
</p>

<p>
SolidWorks-style computation is also prospective, not retrospective. In other words, the goal of the simulation is to generate subsequent experimental hits, not figures for publication, meaning that successful computational studies might never even be reported. This is different from the DFT section of the average organic chemistry paper, which is typically performed by a different team after all experimental results are complete. This isn’t bad, but <i>ex post</i> studies are different from actually using computations <i>ex ante</i> to design molecules.
</p>

<p>
I don’t mean to suggest that the SolidWorks paradigm is objectively correct: there are many ways in which theory, computation, and experiment can usefully interact, and I think it’s great that there are scientists using careful <i>ex post</i> computations to interpret perplexing experimental results or running massive virtual screens to design new molecules entirely <i>in silico</i>. I myself have worked on plenty of projects like this and hope to conduct more in the future.
</p>

<p>
But I do think that SolidWorks-style computation is pretty underrated today. There are few computational tools that non-experts can really use, and the average experimental scientists might not interact with computation even once in an average week (except perhaps when meeting with someone from a different lab or team). Even when experimentalists have the technical skills to run calculations, the friction involved in connecting to a computing cluster, generating input files, monitoring jobs, etc often makes it impractical to really run calculations and experiments in tandem.
</p>

<p>
In fact, I’d argue that the most useful predictive computational tool for organic chemists has probably been the ChemDraw “Predict NMR” button. The predictions are laughably crude by today’s standards, but ChemDraw NMR has a few key advantages: (1) you don’t have to program anything or look at a terminal window to use it, (2) there aren’t any options for end users to mess around with, so you can’t do anything wrong, and (3) it runs instantly from a software package everyone already has, so it fits right into your workflow. These factors are collectively more important than accuracy—ChemDraw NMR is accurate enough to be useful, and far more convenient than fancier approaches. 
</p>

<figure>
  <img class=centered-img src="https://bitesizebio.com/wp-content/uploads/2016/11/Figure-6-NMR-Prediction.jpg" style="width:450px;" />
  <figcaption>A screenshot of ChemDraw's NMR prediction widget.</figcaption>
</figure>

<p>
This seems like a scenario where publication pressure leads to misaligned incentives. Scientific publications emphasize novelty, accuracy, and performance, not pragmatic considerations like “how easy is it to run this software in the middle of the workday” or “how confusing are the parameters to understand.” And for pioneering computational workflows that ought not to be run without a deep understanding of the science, that’s probably appropriate. But pragmatic considerations matter for casual users. 
</p>

<p>
If it’s not obvious by now, one of our big visions for Rowan is “SolidWorks for organic chemistry”—to the extent that there are people who are designing and creating new molecules, we think that it’s important that they are able to think intelligently about the molecules that they’re designing. This means making software that can deliver actionable insights while being fast and simple enough for experimentalists to use. While this is a massive project, it’s not impossibly large, and we’re optimistic that Rowan can quickly become helpful to experimental chemists. If you think this vision is exciting and have ideas for how we can bring it to life, let us know!
</p>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20240105_phys_org.html'>Physical Organic Chemistry: Alive or Dead?</a></h2><i>January 5, 2024</i>
<p>
In <a href=https://corinwagen.github.io/public/blog/20240103_norbornyl.html>Wednesday’s post</a>, I wrote that “traditional physical organic chemistry is barely practiced today,” which <a href=https://twitter.com/FindlaterGroup/status/1742734408782876949>attracted some controversy on X</a>. Here are some responses:
</p>

<ul>
<li>
“POC has evolved in many directions and its concepts are widely used, e.g., in host-guest chem, org syn,  materials sci, drug discovery.” - <a href=https://twitter.com/JorgensenWL/status/1742963638351089825>Bill Jorgensen</a>
</li>
<li>
“There is still a lot of absolutely gorgeous classical phys org done with organometallic and enzymatic reactions. The molecules have changed, the ideas are the same.” - <a href=https://twitter.com/dasingleton/status/1742752687853056140>Dan Singleton</a>
</li>
<li>
“It makes no sense. Looking at orbitals, measuring KIE, studying mechanisms, all traditional PhysOrgChem. And ML in OrgChem is nothing more than Curtin-Hammett on steroids.” - <a href=https://twitter.com/KozuchSebastian/status/1742795358680293550>Sebastian Kozuch</a>
</li>
<li>
“Hard core classical phys-org maybe, but structure-activity relationships are alive and well across all chemistry disciplines. These have their origin in phys-org and use so many fundamental principles I learned as a PhD student studying carbocation and free radical reactions.” - <a href=https://twitter.com/RacerPolyLab/status/1742909928291836067>@RacerPolyLab</a>
</li>
<li>
“I've attend 10 Phys Org GRC meetings since 1999 &amp; chaired 2015. I'm OK with ‘traditional phys. org. chemistry’ being barely practiced. It was dying–2001 saw 79 attendees, then the area morphed into phys. org. of organometallics, supramolecular, biomolecules. Fields evolve or die.” - <a href=https://twitter.com/UOHaleyLab/status/1742748763670843722>Michael Haley</a>
</li> 
</ul>

<p>
(There are plenty more responses; if I didn’t list yours, sorry!)
</p>

<p>
For the most part, I agree with these responses. Physical organic thinking has permeated organic chemistry and adjacent fields: George Whitesides has probably <a href=https://onlinelibrary.wiley.com/doi/10.1002/ijch.201500061>the best piece on this topic</a>, in which he argues that the essence of physical organic chemistry is “a general, and remarkably versatile, method for tackling complex problems,” not anything about chemistry per se, and consequently that the physical organic mindset can be applied to problems in all manner of fields. Viewed from this angle, we might say that physical organic chemistry hasn’t disappeared at all—instead, it’s become so commonplace that we forget to acknowledge it as distinctive at all.</p>

<p>
Looking through the organic chemistry curriculum, too, suggests that physical organic chemistry is here to stay. Lots of the ideas that we teach to undergraduates, like molecular orbital theory and structure–activity relationships, were once distinctively the domain of physical organic chemists. Textbooks from before the apotheosis of physical organic chemistry (I have an old copy of Fieser &amp; Fieser, for instance) are structured in a completely different way, not by mechanism but by functional group, while today many undergraduate organic classes discuss S<sub>N</sub>1/S<sub>N</sub>2 mechanisms in their first semester.
</p>

<p>
So, was I entirely wrong to claim that traditional physical organic chemistry is a dying art? I don’t think so. Despite all the successes of physical organic chemistry, it seems to me that something has been lost between the time of the norbornyl cation controversy and today. The sorts of elegant kinetic experimentation and argumentation that Winstein and others employed in their papers are now rare: take, for instance, <a href=https://pubs.acs.org/doi/10.1021/ja01583a022>this famous paper</a> distinguishing between contact ion pairs and solvent-separated ion pairs. How many scientists today still do experiments like this? There are certainly names that come to mind, but from where I sit it seems to be an increasingly niche skillset.
</p>

<figure>
  <img class=centered-img src=../img/20240105_kinetics.png style="width:350px;" />
</figure>

<p>
I don’t want to fall into the trap of idolizing the past for no reason; there are plenty of techniques which have been forgotten by chemistry because there are better ways of doing the same thing today. Chemists used to estimate molecular weight by dissolving a known mass of sample and measuring the boiling point elevation induced. Now we have mass spectrometry, so nobody uses the boiling point method any more, and I don’t see this as a great tragedy.
</p>

<p>
But kinetics, and more generally the sort of careful physical organic chemistry practiced by participants in the norbornyl cation debate, doesn’t seem to have such a simple replacement. Computation is the most obvious candidate, but we’re still a long way away from being able to predict mechanisms accurately <i>in silico</i>; in mechanistic chemistry, <a href=https://pubs.acs.org/doi/pdf/10.1021/ja5111392>experiments still reign supreme</a>. Kinetic isotope effects are much easier to measure than they were back in Winstein’s day, but they’re hardly routine experiments (and easy to get wrong). The rigor and precision with which old-school physical organic chemistry approached mechanistic problems can still be found today, but it seems harder and harder to find.
</p>

<p>
It might have been inevitable that physical organic chemistry was always going to evolve away from incredibly detailed studies of simple reactions on simple molecules—just as biology has largely shifted from ecology and taxonomy to cell biology and biochemistry, organic chemistry too must change in order to keep working on the most interesting problems. And perhaps there's some truth to the argument that the old-school style of painstaking mechanistic study just isn't worth the effort and deserves to be de-emphasized. But it does seem to me that parts of the tradition of physical organic knowledge (to borrow <a href=https://samoburja.com/on-the-loss-and-preservation-of-knowledge/>Samo Burja’s phrasing</a>) is being slowly lost to time, despite the fact that lots of really good physical organic chemistry is still being done today on all sorts of problems (enzymatic chemistry, organometallic chemistry, catalysis, heterogenous catalysis, chemical biology, &amp;c), and that makes me sad.
</p>
</div><div class='previous-link'><a href='blog_p4.html'>previous page</a></div><div class='next-link'><a href='blog_p6.html'>next page</a></div><br>
  </body>
  <br>
  <footer>
    <a href="mailto:corin.wagen+blog@gmail.com">email</a>
    <a href="https://github.com/corinwagen">github</a>
    <a href="https://twitter.com/CorinWagen">x</a>
    <a href="https://scholar.google.com/citations?user=SW0Uhs0AAAAJ">google scholar</a>
    <div style="float:right;">
      <a href="/rss.xml">rss</a>
      <a href="https://cwagen.substack.com">substack</a>
    </div>
  </footer>
</html>
