<!DOCTYPE html>
<html>
  <head>
    <title>
      Blog
    </title>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta name="language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="../../static/style.css">

    <link rel="alternate" type="application/rss+xml" title="RSS feed for the blog" href="/rss.xml">

    <!--google-->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MTNZ0ZSG3W"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-MTNZ0ZSG3W');
    </script>

  </head>
  <body>
    <ul class="menu-list">
      <li class="menu-item"><a href="index.html" class="menu-link menu-title">Corin Wagen</a></li>
      <li class="menu-item"><a href="index.html#about" class="menu-link">About</a></li>
      <!--<li class="menu-item"><a href="index.html#projects" class="menu-link">Projects</a></li>-->
      <!--<li class="menu-item"><a href="index.html#past_work" class="menu-link">Past Work</a></li>-->
      <li class="menu-item"><a href="index.html#pubs" class="menu-link">Papers</a></li>
      <li class="menu-item">
        <a href="blog_p1.html" class="menu-link">Blog</a>
        <a href='archive.html' class="menu-link">(Archive)</a>
      </li>
    </ul>
    <h1 class='blogroll-header'>Blog</h1><div class='previous-link'><a href='blog_p5.html'>previous page</a></div><div class='next-link'><a href='blog_p7.html'>next page</a></div><br><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20231321_books.html'>Books from 2023</a></h2><i>December 31, 2023</i>
<p>
(Previously: <a href=https://corinwagen.github.io/public/blog/20221231_books.html>2022</a>)
</p>

<b>#1. Tony Fadell, <i>Build</i></b>
<br>
<b>#2. Giff Constable, <i>Talking To Humans</i></b>
<br>
<b>#3. Ben Horowitz, <i>The Hard Thing About Doing Hard Things</i></b>
<br>
<b>#4. Dale Carnegie, <i>How To Win Friends And Influence People</i></b>

<p>
Sounds Machiavellian, but actually quite wholesome: a “dad book,” as my friend called it.
</p>

<b>#5. Ben Patrick, <i>Knee Ability Zero</i></b>.
<br>
<b>#6. Neal Stephenson, <i>The Diamond Age</i></b>

<p>
<i>Snow Crash</i> was much worse upon rereading as an adult, but <i>The Diamond Age</i> was a bit better: in particular, I didn’t really appreciate the “speculative governance futurism”/”comparative cultural criticism” facets of the novel when I read this in high school.
</p>

<b> #7. Richard Hamming, <i> The Art of Doing Science and Engineering</i></b>

<p>
I reviewed this <a href=https://corinwagen.github.io/public/blog/20230516_hamming.html>here</a>.
</p>

<b>#8-11. Brandon Sanderson, <i>The Stormlight Archives</i></b>

<p>
Many great works of literature are notable for their brevity: when you read Hemingway, or <i>Dubliners</i>, or Flannery O’Connor, you know that every sentence has been crafted with care. Giant fantasy novels like <i>Wheel of Time</i> (which I read last year) or <i>The Stormlight Archives</i> work differently. There are entire chapters which are probably extraneous, whole characters and plot arcs which exist merely to bring out certain traits or pieces of information.
</p>

<p>
But there are unique joys to megafiction: sitting down and reading hundreds of pages of a good story is relaxing in a way that other books simply aren’t. In my own life, I’ve found that I’m much better about making time to read when I’m in the middle of an engaging novel than when I’m reading theology or histories of feudalism. Narrative-driven “easy reading” has a bad reputation amongst the literati; in a world where all fiction is competing against screens for engagement, it shouldn’t.
</p>

<b>#12. Antonio Garcia Martínez, <i>Chaos Monkeys</i></b>

<p>
I reviewed this <a href=https://corinwagen.github.io/public/blog/20230530_chaos_monkeys.html>here</a>.
</p>

<b> #13. Tom Holland, <i>Rubicon</i></b>
<br>
<b> #14. Tom Holland, <i>Dynasty</i></b>
<br>
<b> #15. Czeslaw Milocz, <i>The Captive Mind</i></b>

<p>
Fantastic; I probably would have liked this even more if I were still in school.
</p>

<b> #16. C.S. Lewis, <i>That Hideous Strength</i></b>

<p>
I didn’t like this when I was a kid, but I like it now: in many respects <i>THS</i> can be viewed as a book-length exploration of the ideas in “The Inner Circle,” with a garnish of medieval cosmology here and there (<a href=http://www.planetnarnia.com/>see also</a>).
</p>

<b> #17. Kazuo Ishiguro, <i>Klara and the Sun</i></b>
<br>
<b> #18. Mike Cosper, <i>Recapturing the Wonder</i></b>
<br>
<b> #19. Mairtin O Caidhan, <i>Graveyard Clay</i></b>

<p>
Tyler Cowen recommended this book, but I didn’t love it.
</p>

<b> #20. Ursula K. LeGuin, <i>The Dispossessed</i></b>
<br>
<b> #21. Marty Cagan, <i>Inspired</i></b>
<br>
<b> #22. Ernst Junger, <i>On the Marble Cliffs</i></b>

<p>
This was excellent (h/t <a href=https://regressstudies.substack.com/p/young-lords-and-their-traces>Santi Ruiz</a>).
</p>

<b> #23. Michaeleen Doucleff, <i>Hunt, Gather Parent</i></b>

<p>
I reviewed this book <a href=https://corinwagen.github.io/public/blog/20231106_hgp.html>here</a>.
</p>

<b> #24. David Kirkpatrick, <i>The Facebook Effect</i></b>
<br>
<b> #25. Bill Carr &amp; Colin Bryar, <i>Working Backwards</i></b>

<p>
I reviewed this book <a href=https://corinwagen.github.io/public/blog/20231125_working_backwards.html>here</a>.
</p>

<b> #26. Geoffrey Chaucer, <i>The Canterbury Tales</i></b>

<p>
The best book I read this year by a mile; far better than I remembered. While many of <i>The Canterbury Tales</i> work pretty well as literature, they’re even better when viewed also as history. It’s rare to be able to read something from 800 years ago that’s legitimately funny and interesting.
</p>

<p>
Reading Chaucer fills me with questions about the medieval mind. The stories are steeped in Christianity, as one might expect. Any argument goes back to the Bible, even those among animals, and Chaucer assumes a level of familiarity with e.g. the Psalms far exceeding that of most modern Christians. Yet at the same time the Greco-Roman world looms large: Roman gods appear as plot characters in three tales (the Knight’s Tale, the Merchant’s Tale, and the Manciple’s Tale), and Seneca is viewed as a moral authority on par with Scripture. I’m curious how all these beliefs and ideas fit together and welcome any recommendations on this subject. (<i>The Discarded Image</i> is already on my list.)
</p>

<b> #27. Gabrielle Zevin, <i>Tomorrow and Tomorrow and Tomorrow</i></b>

<p>
My wife recommended this book to me. I thought this would be a relaxing break from the November startup grind, but in fact it features a bunch of obsessed programmers working around the clock for months—a poor choice but a good novel.
</p>

<b> #28. Jessica Livingston, <i>Founders at Work</i></b>
<br>
<b> #29. Neal Stephenson, <i>Seveneves</i></b>
<br>
<br>
<p>
Overall, about a third of the books I read were startup-related: most of them were pretty bad, but even bad business/startup books are probably useful from the viewpoint of cultural immersion. Academic science is quite different from the startup ecosystem, and to the extent that cultural arbitrage is possible (in either direction), I need to become proficient in startup culture.
</p>

<p>
I’m not sure why the median business book is so bad—perhaps business people are too willing to spend money on books and not picky enough, or perhaps MBA types generally lack knowledge about the humanities, which makes both supply and demand worse.
</p>

<p>
(The median Christian book is also pretty bad. One unifying hypothesis: both pastors and businesspeople often have wise insights into specific situations, personal or business, but these insights aren’t readily generalizable into book form. Being able to give good advice doesn’t mean you should write an “advice book.”)
</p>

<p>
As always, book recommendations are welcome, particularly on the topics of medieval history/culture, software engineering, or startups. Apologies for the infrequent posting as of late, and happy new year!
</p>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20231201_sutton.html'>Bitter Lessons in Chemistry</a></h2><i>December 1, 2023</i>
<br>
<br>
<p class=epigraph>
“And I took the little scroll from the hand of the angel and ate it. It was sweet as honey in my mouth, but when I had eaten it my stomach was made bitter.”
</p>
<p class=epigraph-byline>
–Revelation 10:10
</p>

<figure>
  <img class=centered-img src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Ottheinrich_Folio293r_Rev10.jpg/1024px-Ottheinrich_Folio293r_Rev10.jpg style="width:450px;" />
</figure>

<p>
As machine learning becomes more and more important to chemistry, it’s worth reflecting on Richard Sutton’s 2019 blog post about the “bitter lesson.” In <a href=http://www.incompleteideas.net/IncIdeas/BitterLesson.html>this now-famous post</a>, Sutton argues that “the biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin.” This might sound obvious, but it’s not:
</p>

<blockquote>
[The bitter lesson] is a big lesson. As a field, we still have not thoroughly learned it, as we are continuing to make the same kind of mistakes. To see this, and to effectively resist it, we have to understand the appeal of these mistakes. We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. <u>The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.</u> <i>(emphasis added)</i>
</blockquote>

<p>
How might the bitter lesson be relevant in chemistry? One example is computer-assisted retrosynthesis in organic synthesis, i.e. figuring out how to make a given target from commercial starting materials. This task was first attempted by Corey’s LHASA program (<a href=https://pure.mpg.de/rest/items/item_2549520/component/file_3325899/content>1</a>, <a href=https://www.nobelprize.org/uploads/2018/06/corey-lecture.pdf>2</a>), and more recently has been addressed by Bartosz Gryzbowski’s <a href=https://www.cell.com/chem/pdf/S2451-9294(18)30085-8.pdf>Synthia</a>. Despite considerable successes, both efforts have operated through manual encoding of human chemical intuition. If Sutton is to be believed, we should be pessimistic about the scalability and viability of such approaches relative to pure search-based alternatives in the coming years.
</p>

<p>
Another example is machine-learned force fields (like ANI or NequIP). While one could argue that equivariant neural networks like <i>e3nn</i> aren’t so much incorporating domain-specific knowledge as exploiting relevant symmetries (much like convolutional neural networks exploit translational symmetry in images), there’s been a movement in recent years to combine chemistry-specific forces (e.g. long-range Coulombic forces) with neural networks: Parkhill’s <a href=https://pubs.rsc.org/en/content/articlelanding/2018/sc/c7sc04934j>TensorMol</a> did this back in 2018, and more recently <a href=https://www.nature.com/articles/s41467-021-27340-2>Dral</a>, <a href=https://arxiv.org/abs/2301.08734>Piquemal</a>, and <a href=https://pubs.acs.org/doi/full/10.1021/jacs.3c07628>Levitt &amp; Fain</a> (<a href=https://twitter.com/olexandr/status/1730604569028092081>among others</a>) have published on this as well. While I’m no expert in this area, the bitter lesson suggests that we should be skeptical about the long-term viability of efforts, and instead just throw more data at chemistry-agnostic models. 
</p>

<p>
A key assumption of the bitter lesson is that “over a slightly longer time than a typical research project, massively more computation inevitably becomes available.” This idea has also been discussed by Andrej Karpathy, who <a href=https://karpathy.github.io/2022/03/14/lecun1989/>reproduced</a> Yann LeCun’s landmark 1989 backpropagation paper last year using state-of-the-art techniques and reflected on how the field has progressed since then. In particular, Karpathy discussed how the last three decades of progress in ML can help us envision what the next three decades might look like:
</p>

<blockquote>
Suppose that the lessons of this exercise remain invariant in time. What does that imply about deep learning of 2022? What would a time traveler from 2055 think about the performance of current networks?
<ul>
<li>
2055 neural nets are basically the same as 2022 neural nets on the macro level, except bigger.
</li>
<li>
Our datasets and models today look like a joke. Both are somewhere around 10,000,000X larger.
</li>
<li>
One can train 2022 state of the art models in ~1 minute by training naively on their personal computing device as a weekend fun project.
</li>
<li>
Today’s models are not optimally formulated, and just changing some of the details of the model, loss function, augmentation or the optimizer we can about halve the error.
</li>
<li>
Our datasets are too small, and modest gains would come from scaling up the dataset alone.
</li>
<li>
Further gains are actually not possible without expanding the computing infrastructure and investing into some R&D on effectively training models on that scale.
</li>
</ul>
</blockquote>

<p>
If we take this seriously, we might expect that chemical ML will not be able to advance much farther without bigger datasets and bigger models. Today, experimental datasets rarely exceed 10<sup>4</sup>–10<sup>5</sup> data points, and even computational datasets typically comprise 10<sup>7</sup> data points or fewer—compare this to the ~10<sup>13</sup> tokens <a href=https://www.reddit.com/r/LocalLLaMA/comments/14wbmio/gpt4_details_leaked/>reportedly used to train GPT-4</a>! It’s not obvious how to get experimental datasets that are this large. HTE and robotics will help, but five orders of magnitude is a big ask. Even all of Reaxys doesn’t get you to 10<sup>8</sup>, poor data quality notwithstanding. (It’s probably not a coincidence that DNA-encoded libraries, which can actually have hundreds of millions of data points, also pair nicely with ML: I’ve written about this <a href=https://corinwagen.github.io/public/blog/20230403_industry.html>before</a>.)
</p>

<p>
In contrast, computation permits the predictable generation of high-quality datasets. If Sutton is right about the inevitable availability of “massively more computation,” then we can expect it to become easier and easier to run hitherto expensive calculations like DFT in parallel to generate huge datasets, and to enable more and more downstream applications like chemical machine learning. With the right infrastructure (like Rowan, hopefully), it should be possible to turn computer time into high-quality chemical data with almost no non-financial scaling limit: <a href=https://pubs.acs.org/doi/10.1021/ci300415d>we’re certainly not going to run out of molecules</a>.
</p>

<p>
The advent of big data, though, heralds the decline of academic relevance. Julian Togelius and Georgios Yannakakis wrote about this earlier this year in a piece on <a href=https://arxiv.org/abs/2304.06035?s=03>“survival strategies for depressed AI academics,”</a> which discusses the fact that “the gap between the amount of compute available to ordinary researchers and the amount available to stay competitive is growing every year.” For instance, GPT-4 reportedly cost c. $60 million to train, far surpassing any academic group’s budget. Togelius and Yannakakis provide a lot of potential solutions, some sarcastic (“give up”) and others quite constructive—for instance, lots of interpretability work (<a href=https://transformer-circuits.pub/2023/monosemantic-features/index.html>like this</a>) is done on toy models that don’t require GPT-4 levels of training. Even the most hopeful scenarios they present, however, still leave academics with a rather circumscribed role in the ML ecosystem. 
</p>
 
<p>
The present academic era of chemical machine learning can thus be taken as a sign of the field’s immaturity. When will chemical ML reach a Suttonian era where scaling is paramount and smaller efforts become increasingly futile? I’m not sure, but my guess is that it will happen when (and only when) there are clear commercial incentives for developing sophisticated models, enabling companies to sink massive amounts of capital into training and development. This clearly hasn’t happened yet, but it also might not be as far away as it seems (<a href=https://www.nature.com/articles/s41586-023-06735-9>cf.</a>). It’s an interesting time to be a computational chemist…
</p>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20231125_working_backwards.html'>Book Review: Working Backwards</a></h2><i>November 25, 2023</i>
<p>
I took a pistol course in undergrad, and while I was a poor marksman I enjoyed the experience. In particular, I was surprised by how meditative the act of shooting was. As our instructor explained, much of good shooting comes down to not doing anything when you pull the trigger. When you’re not firing, it’s easy to point a gun at a target and line up the sights, but as you pull the trigger you subconsciously anticipate the noise and movement of the pistol blast, which makes you flinch and pull the gun off-target. Being a good shooter thus requires consciously learning to counteract what your instincts tell you to do.
</p>

<p>
If you believe Bill Carr and Colin Bryar’s book on Amazon, <a href=https://www.amazon.com/Working-Backwards-Insights-Stories-Secrets/dp/1250267595><i>Working Backwards</i></a>, Amazon’s success can be understood in similar terms. According to Carr and Bryar, Amazon alone among the West Coast zaibatsu has succeeded not because of some big technical or social insight (Google Search, Windows) but because of a long series of canny business decisions. Bezos has said something similar: “Amazon doesn't have one big advantage, so we have to braid a rope out of many small advantages.” The implication is that you too can build an Amazon-quality firm; you don’t need any flashes of mad genius, just the ability to eke out small advantages through savvy management.
</p>

<p>
(This might seem like an insane claim, but it’s worth noting that Amazon has indeed launched a ton of successful and loosely coupled businesses: in addition to their core commerce business, there’s AWS, Amazon Robotics, Kindle, Prime Video, Fire TV, and a bunch of other stuff. Contrast this to Google’s recent track record…)
</p>

<p>
What’s more, Carr and Bryar go on to argue that Amazon’s business acumen is driven not by some inscrutable Bezos magic but by adherence to a simple set of principles. And these principles aren’t esoteric or Amazon-specific—almost any business can follow them. The reason so few businesses have copied Amazon’s success is simply because each principle defies human nature in some way. Just like pistol shooting requires one to unlearn one’s instincts and pull the trigger without moving any other muscles, being an “Amazonian” business requires discarding what you think you understand about building a business and going back to basics.
</p>

<p>
So, what are these magic principles?
</p>

<h2>
1. Focus on Customers, Not Competitors
</h2>

<p>
Focusing on competitors is human nature—in a competition, we judge ourselves based on our rivals, and like to imagine how we’ll defeat them. But success in business comes from satisfied customers, not vanquished foes, and keeping a relentless focus on users/customers is key to building something great. This is hardly Amazon-specific wisdom: “build something people want” is <a href=https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice>venerable YC advice</a>, and <i>Zero to One</i> also makes the point that competition is bad and focusing on it counterproductive. Perhaps the fact that so many different people feel the need to emphasize this point speaks to how counterintuitive it is: were it widely adopted, it wouldn’t be repeated.
</p>

<p>
Plenty of people outside business also get this wrong. A few weeks ago, a friend was explaining how he feels that many computational chemists are making software not for users but for other computational chemists. This is a case in which writing papers leads to different incentives than releasing products: papers are reviewed by one’s peers (other computational chemists), while products are ultimately reviewed by users. Hopefully Rowan doesn’t make this mistake…
</p>

<h2>
2. “Bar Raisers”: External Vetos in Hiring
</h2>

<p>
Amazon includes a person called a “Bar Raiser” involved in all hiring decisions, who isn’t the hiring manager (the person who is trying to acquire a new team member) but who has final veto power on any potential hire. The hiring manager is hiring because they need help in the short term, so they’re typically willing to engage in wishful thinking and lower their standards—but the Bar Raiser (who’s just another Amazon employee, with a bit of extra training) has no such incentives and can make sure that no poor performers are hired, which is better for Amazon in the long run.
</p>

<p>
I like this idea because it’s a nice example of mechanism design: just a little bit of internal red-teaming which (according to the book) works quite well. (Red teaming is another one of those “good but counterintuitive practices” which seems underutilized—see <a href=https://open.substack.com/pub/statecraftnotes/p/how-to-predict-the-future?r=5jsaw&selection=302a6711-1b29-4791-aedc-0320932bac7a&utm_campaign=post-share-selection&utm_medium=web>the discussion</a> in a recent <i>Statecraft</i> interview.)
</p>

<h2>
3. Problem-Focused, Not Skills-Focused
</h2>

<p>
It’s natural to think about what we should do next in terms of what we’re good at: “I’m good at X, how can I use X to solve a problem?” Carr and Bryar argue that “working forwards” in this way is stupid, because only at the end do you think about who (if anyone) might care if you succeed. “Working backwards” from problem to solution is a much better strategy: first you articulate what you might need to accomplish to produce a compelling solution, and then you think about if you can do it. Inside Amazon, most potential new projects start out by drafting what the press release might be if the project were finished, and then working backwards from the press release to what the product must be. (Most products envisioned in this way never actually get developed, which is exactly the point of the exercise.)
</p>

<p>
<a href=https://intra.ece.ucr.edu/~rlake/Whitesides_writing_res_paper.pdf>George Whitesides</a> has advocated for a similar way to approach science: first write the paper, then conduct the experiments. Lots of scientists I know find this repulsive, or contrary to how science should be practiced, but it always seemed shrewd to me—if you can’t make an interesting paper out of what you’re doing, why are you doing it? (Exploratory work can be tough to outline in this way, but there should be several potential papers in such cases, not none.)
</p>

<h2>
4. Single-Threaded Leadership
</h2>

<p>
As organizations scale, it becomes tougher and tougher to allow teams to work autonomously, and responsibility and authority for almost all projects ends up bestowed upon the same small number of people. This makes insightful innovation hard: to quote Amazon SVP of Devices Dave Limp, “the best way to fail at inventing something is by making it somebody’s part-time job.” Amazon’s solution is the idea of single-threaded leadership (STL, probably someone’s idea of C++ humor). Organizations need to be arranged such that individual teams can respond to their problems intelligently and independently, planning and shipping features on their own, and each team needs to have a “single-threaded leader” solely responsible for leading that team.
</p>

<p>
Instituting STL takes a good amount of initial planning, since dividing up a giant monolith into loosely coupled components is tough both for software and for humans, and it’s not in the nature of authorities to relinquish control. If done properly, though, this allows innovation to happen much faster than if every decision is bottlenecked by reliance on the C-suite. (It’s sorta like federalism for businesses.)
</p>

<p>
This idea matters for labs, too: some research groups rely on their PI for scientific direction in every project, while others devolve a lot of authority to individual students. The latter seem more productive to me.
</p>

<h2>
5. Bias Towards Action
</h2>

<p>
Humans are by nature conservative, and sins of commission frequently feel worse than sins of omission—making a bad decision can cost you your job, while not making a good decision often goes unnoticed (the <a href=https://marginalrevolution.com/marginalrevolution/2015/08/is-the-fda-too-conservative-or-too-aggressive.html>“invisible graveyard”</a>). To counteract this, Amazon expects leaders to display a “Bias for Action.” In their words:
</p>

<blockquote>
Speed matters in business. Many decisions and actions are reversible and do not need extensive study. We value calculated risk-taking.
</blockquote>

<p>
Again, this echoes classic startup advice: “launch now,” “do things that don’t scale,” &amp;c.
</p>

<h2>
6. No Powerpoint!
</h2>

<p>
In June 2004, Amazon banned PowerPoint presentations from meetings, instead expecting presenters to compose six-page documents which the entire team would read, silently, at the beginning of each meeting. Why? A few reasons:
</p>

<ul>
<li>
PowerPoint lends itself poorly to complex or nuanced ideas, whereas written documents can contain more information and more complete chains of reasoning.
</li>
<li>
PowerPoint leads to “slick,” well-rehearsed presentations where the presenter’s style and charisma matters as much as the underlying ideas.
</li>
<li>
Writing enforces greater clarity of thought than speaking.
</li>
<li>
PowerPoint makes the audience passive, while reading makes the audience active participants in the ideas. People like to be passive, and it’s fun to hear an inspiring presentation, but in the long run it’s better for everyone to actually engage.
</li>
</ul>

<p>
I’m pretty sympathetic to these criticisms. Most high-stakes academic events today revolve around oral presentations, not papers—although papers still matter, doctorates, job offers, and tenure are awarded largely on the merits of hour-long talks (<a href=https://www.youtube.com/watch?v=n7HeQGQQ0q8>e.g.</a>). As a result, I spent a ridiculous amount of my PhD just refining and hearing feedback on my presentations, much of which had nothing to do with the underlying scientific ideas. Perhaps this focus on showmanship over substance explains why so little science today seems genuinely transformational. (It’s also worth noting that presenting, much more so than writing, favors charismatic Americans over the meek or foreign.)
</p>

<p>
There are, of course, more than just these six ideas in <i>Working Backwards</i>, but I think this gives a pretty good sense of what the book is like. Overall, I’d recommend this book: it was interesting throughout (unlike most business-y books), and even if nothing in its covers is truly new under the sun, the ideas inside are good enough to be worth reviewing periodically.
</p>
</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20231106_hgp.html'>Book Review: Hunt, Gather, Parent</a></h2><i>November 6, 2023</i>
<br>
<br>
<p class=epigraph>
“Like arrows in the hand of a warrior are the children of one's youth.”
</p>
<p class=epigraph-byline>
–Psalm 127:4
</p>

<figure>
  <img class=centered-img src=../img/20231106_gaugain.jpg style="width:300px;" />
  <figcaption>
    <i>Mata Mua</i>, by Paul Gaugain (1892), another Westerner looking for enlightenment among “venerable cultures.”
  </figcaption>
</figure>

<p>
What if our most fundamental assumptions about parenting were wrong? That’s the question that Michaeleen Doucleff’s 2021 book <i>Hunt, Gather, Parent</i> tries to tackle. <i>Hunt, Gather, Parent</i> (henceforth <i>HGP</i>) documents Doucleff’s journey to “three of the world’s most venerable cultures”—the Maya, the Inuit, and the Hadzabe (in Tanzania)—to learn about how they parent their children, and offers helpful advice for parents envious of the kind, helpful, and responsible children she observes.
</p>

<p>
Doucleff’s writing hits some familiar beats: critiques of helicopter parenting, distrust of endless after-school activities, and laments about the atomization of our society (<a href=https://web.archive.org/web/20230306232837/https://www.theatlantic.com/magazine/archive/2020/03/the-nuclear-family-was-a-mistake/605536/>cf.</a>). But there are plenty of unexpected insights too. I was convicted by her account of how Hadzabe children are given autonomy and responsibilities from a young age without being either ignored or micromanaged: her vision of a middle ground between <i>K</i>-selected “helicopter parents” and <i>r</i>-selected “free-range parents” was compelling.
</p>

<p>
There’s a lot to like about the parenting depicted in <i>HGP</i>. For instance, Doucleff highlights how toddlers’ innate eagerness to help is used by the Maya to build a culture of helpfulness (the virtue she calls <i>acomedido</i>) which lasts as they grow, whereas American parents generally disregard help from a toddler and thus teach kids that their help isn’t valued. On the other hand, I’m not compelled by her account of how the Inuit view conflict with their children:
</p>

<blockquote>
Inuit see arguing with children as silly and a waste of time… because children are pretty much illogical beings. When an adult argues with a child, the adult stoops to the child’s level… During my three visits to the Arctic, I never once witness a parent argue with a child. I never see a power struggle. I never hear nagging or negotiating. Never.
</blockquote>

<p>
I admit that getting into a shouting match with your toddler is pointless, but assuming that children are innately devoid of logic seems like an overreaction! 
</p>

<p>
Astute readers might be getting bothered by now, though: why are the Maya—who ruled a swath of Central America for over a millennium—included in a book ostensibly about “hunter-gatherers and other indigenous cultures with similar values”? This highlights a deeper issue I have with <i>HGP</i>, which is that it partitions the world neatly into “Westerners” and “everyone else,” citing Joseph Heinrich’s <a href=https://en.wikipedia.org/wiki/The_WEIRDest_People_in_the_World><i>The WEIRDest People in the World</i></a> as its justification. While there are certainly many ways in which our own culture is distinct, ours is but one among many, and there’s plenty of cultural diversity about which <i>HGP</i> is silent.
</p>

<figure>
  <img class=centered-img src=../img/20231106_tikal.jpg style="width:450px;" />
  <figcaption>
    The ruins of Tikal.
  </figcaption>
</figure>

<p>
For instance, Doucleff argues that in other cultures “parents build a relationship with young children… that’s based in cooperation instead of conflict, trust instead of fear.” I’m skeptical about this claim—what might we learn from some other non-WEIRD societies? 
</p>

<ul>
<li>
“In the Mendocino Codex… the daily life of Aztecs was described, including a common form of punishment for children. The Codex has a drawing of a father punishing his 11-year-old son by making the boy inhale smoke emanating from dry chiles roasting on the hearth. In the same drawing, a mother threatens her 6-year-old daughter with the same punishment” (<a href=https://journals.ashs.org/hortsci/downloadpdf/journals/hortsci/34/5/article-p809.xml>Paul Bosland</a>)
</li>

<figure>
  <img class=centered-img src=../img/20231106_codex.jpg style="width:450px;" />
  <figcaption>
    Not exactly “gentle parenting”!
  </figcaption>
</figure>

<li>
“Roman law understands the legal power of the <i>pater familias</i> within the familia to be absolute, to the point of being able to put any member to death (this seems to have almost never happened, but it was legally permitted)” (<a href=https://acoup.blog/2023/07/21/collections-how-to-roman-republic-101-part-i-spqr/>Bret Devereaux</a>)
</li>
<li>
Yan Zhitui (Northern and Southern Dynasties, late 6th century) writes that “…as soon as a baby can recognize facial expressions and understand approval and disapproval, training should be begun so that he will do what he is told to do and stop when so ordered. After a few years of this, punishment with the bamboo can be minimized, as parental strictness and dignity mingled with parental love will lead the boys and girls to a feeling of respect and caution and give rise to filial piety. I have noticed about me that where there is merely love without training this result is never achieved.” (<a href=http://afe.easia.columbia.edu/ps/cup/yan_house_instructions.pdf>quoted here</a>)
</li>
</ul>

<p>
(Granted, these cultures aren’t “indigenous,” but then neither are the Maya.)
</p>

<p>
Doucleff’s focus on partitioning the world into “the West” and “the rest” blinds her to deeper and more interesting questions. The way we parent reflects our values—there are no perfect choices in parenting, just tradeoffs all the way down. Our culture’s valorization of grindset likely helps us instill ambition and a work ethic in our children, but also probably sets them up for depression and other issues down the road. Is this a good trade? Absent an ethical framework, it’s tough to say, but <i>HGP</i> doesn’t even acknowledge the question.
</p>

<p>
There’s a deeper truth here, which is that rejecting the status quo isn’t the same as proposing an alternative. It’s not unfair to read <i>HGP</i> as an account of Doucleff becoming redpilled on parenting and realizing that all her assumptions about how to raise her children might be wrong—but, like many of the newly redpilled, Doucleff lingers too long in her rebellion and doesn’t (in <i>HGP</i>) articulate a satisfying positive vision for what parenting should be. There are innumerable cultures out there, each of which doubtless parents in a different way, and choosing what practices to adopt from each tradition requires wisdom.
</p>

<p>
But these aren’t choices we should want Doucleff to make for us. In the introduction to <i>HGP</i>, Doucleff writes that “as we move outside the U.S., we’ll start to see the Western approach to parenting with fresh eyes,” and this seems true. <i>HGP</i> prompts us to reflect on the choices we make as parents and the ways in which we might choose differently, and even if you disagree with all of Doucleff’s advice it’s worth reading for this experience alone.
</p>

<i>
Thanks to my wife for recommending this book to me, and for helpful discussions.
</i>

</div><div class='blogroll-container'><h2><a class='blogroll-title' href='../../public/blog/20231027_quantum_computing.html'>Quantum Computing for Quantum Chemistry: Short-Term Pessimism</a></h2><i>October 27, 2023</i>
<p>
Quantum computing gets a lot of attention these days. In this post, I want to examine the application of quantum computing to quantum chemistry, with a focus on determining whether there are any business-viable applications today. My conclusion is that while quantum computing is a very exciting scientific direction for chemistry, it’s still very much a realm where basic research and development is needed, and it’s not yet ready for substantial commercial attention.
</p>

<p><i>
Briefly, for those unaware, quantum computing revolves around “qubits” (Biblical pun intended?), quantum analogs of regular bits. They can be in the spin-up or spin-down states, much like bits can hold a 0 or a 1, but they also exhibit quantum behavior like superposition and entanglement. 
</p>

<p>
Algorithms which run on quantum computers can exhibit “quantum advantage,” where for a given problem the quantum algorithm scales better than the classical algorithm, or “quantum supremacy,” where the quantum algorithm is able to tackle problems inaccessible to classical computers. Perhaps the best-known example of this is <a href=https://en.wikipedia.org/wiki/Shor%27s_algorithm>Shor’s algorithm</a>, which enables integer factorization in polynomial time (in comparison to the fastest classical algorithm, which is sub-exponential). 
</p>

<p>
It’s pretty tough to actually make quantum computers in the real world, though. There are many different strategies for what to make qubits out of: isolated atoms, nitrogen vacancy centers in diamonds, superconductors, and trapped ions have all been proposed. The limited number of qubits accessible by state-of-the-art quantum computers, along with the high error rate and short decoherence times, means that practical quantum computation is very challenging today. These challenges are collectively described as “noisy intermediate-scale quantum”, or <a href=https://arxiv.org/abs/1801.00862>NISQ</a>, the world we currently live in. Much effort has gone into trying to find NISQ-compatible algorithms.
</i></p>

<p>
Quantum chemistry, which revolves around simulating a quantum system (nuclei and electrons), seems like an ideal candidate for quantum computing. And indeed, many people have proposed using quantum computers for quantum chemistry, even going so far as to call chemistry the “killer app” for quantum computation. 
</p>

<p>
Here are a few representative claims: 
</p>

<ul>
<li>
“Few fields will get value from quantum computing as quickly as chemistry. Even today’s supercomputers struggle to model a single molecule in its full complexity. We study algorithms designed to do what those machines can’t, and power a new era of discovery in chemistry, materials, and medicine.” (<a href=https://research.ibm.com/topics/quantum-chemistry>IBM</a>)
</li>
<li>
“The problem is that most quantum chemical problems scale exponentially with system size. And classical computers struggle to cope with this exponential scaling. Realistically, they will never enable quantum chemistry to tackle real-world systems.” (<a href=https://www.emdgroup.com/en/research/science-space/envisioning-tomorrow/smarter-connected-world/quantum-computing.html>EMD Group</a>)
</li>
<li>
“Classically built computers simply cannot handle the level of complexity of substances as commonplace as caffeine… But if future chemists embrace quantum computers, they are likely to be a lot luckier.” (<a href=https://www.scientificamerican.com/article/how-quantum-computing-could-remake-chemistry/>Scientific American</a>)
</li>
</ul>

<p>
None of these claims are technically incorrect—there <i>is</i> a level of “full complexity” to caffeine which we cannot model today—but most of them are very misleading. Computational chemistry is doing just fine as a field without quantum computers; I don’t think there are any deep scientific questions about the nature of caffeine that depend on computing its exact electronic structure to the microHartree (<a href=https://pubs.acs.org/doi/abs/10.1021/acs.jpclett.0c02621>competitions between physical chemists notwithstanding</a>).
</p>

<p>
(Some other claims about quantum computing and chemistry border on the ridiculous: I’m not sure what to take away from <a href=https://nam.org/how-quantum-computing-can-combat-forever-chemicals-29001/?stream=policy-legal&s=03>this D-Wave press release</a> which claims that their quantum computer can model 67 million solutions to the problem of “forever chemicals” in 13 seconds. <a href=https://twitter.com/DulwichQuantum>Dulwich Quantum Computing</a>, on Twitter/X, does an excellent job of cataloging such malfeasances.)
</p>

<p>
Nevertheless, there are many legitimate and exciting applications of quantum computing to chemistry. Perhaps the best-known is the variational quantum eigensolver (VQE), developed by Alán Aspuru-Guzik and co-workers <a href=https://www.nature.com/articles/ncomms5213>in 2014</a>. The VQE is a hybrid quantum/classical algorithm suitable for the NISQ era: it takes a Hartree–Fock calculation as the starting point, and then minimizes the energy by optimizing the system classically while evaluating the energy with a quantum computer. (If you want to learn more, there are a number of easy-to-read introductions to the VQE: here’s <a href=https://joshuagoings.com/2020/08/20/VQE/>one</a> from Joshua Goings, and here’s <a href=https://pennylane.ai/qml/demos/tutorial_vqe/>another</a> from Pennylane.)
</p>

<p>
Another approach, more suitable for fault-tolerant quantum computers with large numbers of qubits, is quantum phase estimation. Quantum phase estimation, explained nicely by Pennylane <a href=https://pennylane.ai/blog/2021/11/quantum-computing-for-quantum-chemistry-a-brief-perspective/>here</a>, works like this: given a unitary operator and a state, the state is projected into an eigenstate and the corresponding eigenvalue is returned. (It’s not just projected onto an eigenstate randomly; the probability of returning a given eigenstate is proportional to the overlap with the input state.) This might sound abstract, but the ground-state energy of a molecule is just the smallest eigenvalue of its Hamiltonian, so this provides a route to get exact ground-state energies, assuming we can generate good enough initial states (again, typically a Hartree–Fock calculations).
</p>

<p>
Both of these methods are pretty exciting, since full configuration interaction (the “correct” classical way to get the exact ground-state energy) typically has an <i>O</i>(<i>N</i>!) cost, making it prohibitively expensive for anything larger than, like, N<sub>2</sub>. Further work has built on these ideas: I don’t have the time or skillset to provide a full review of the field, although I’ll note <a href=https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.030307>this work</a> from Head-Gordon &amp; friends and <a href=https://www.nature.com/articles/s41586-021-04351-z>this work</a> from Joonho Lee. (<a href=https://arxiv.org/pdf/2310.03011.pdf#page34>These</a> <a href=https://link.aps.org/accepted/10.1103/RevModPhys.92.015003>reviews</a> provide an excellent overview of different algorithms; I’ll discuss it later on.)
</p>

<p>
Based on the above description, one might reasonably assume that quantum computers offer some sort of dramatic quantum advantage relative to their classic congeners. <a href=https://arxiv.org/abs/2208.02199>Recent work</a> from Garnet Chan (and many coworkers) challenges this assumption, though: 
</p>

<blockquote>
…we do not find evidence for the exponential scaling of classical heuristics in a set of relevant problems. …our results suggest that without new and fundamental insights, there may be a lack of generic EQA [exponential quantum advantage] in this task. Identifying a relevant quantum chemical system with strong evidence of EQA remains an open question.
</blockquote>

<p>
The authors make many interesting points. In particular, they point out that physical systems seem to exhibit locality, i.e. if we’re trying to describe some system embedded in a larger environment to a given accuracy, then there’s some distance beyond which we can ignore the larger environment. This means that there are almost certainly polynomial-time classical algorithms out there for all of computational chemistry, since at some point increasing system size won’t slow our computations down any more. 
</p>

<p>
This might sound abstract, but the authors point out that coupled-cluster theory, which can (in principle) be extended to arbitrary levels of precision, can be made to take advantage of locality and scale linearly with increasing system size or increasing levels of accuracy. Although such algorithms aren’t known for strongly correlated systems, like metallic systems, Chan and co-workers argue based on analogy to strongly correlated model systems that analogous behavior can be expected.
</p>

<figure>
  <img class=centered-img src=../img/20231027_ccsdt.png style="width:550px;" />
  <figcaption>
    Figure 3, showing linear scaling of coupled-cluster theory with respect to increasing accuracy (A) and increasing system size (B)
  </figcaption>
</figure>

<p>
The above paper is making a very specific point—that exponential quantum advantage is unlikely—but doesn’t address whether weaker versions of quantum advantage are likely. Could it still be the case that quantum algorithms exhibit polynomial quantum advantage, e.g. scaling as <i>O</i>(<i>N</i>) while classical algorithms scale as <i>O</i>(<i>N</i><sup>2</sup>)? 
</p>

<p>
<a href=https://www.pnas.org/doi/full/10.1073/pnas.2203533119>Another recent paper</a>, from scientists at Google and QSimulate, addresses this question by looking at the electronic structure of various iron complexes derived from cytochrome P450. They find that there’s some evidence that quantum computers (using quantum phase estimation) will be able to outcompete the best classical methods today (CCSD(T) and DMRG), but it’ll take a really big quantum computer:
</p>

<blockquote>
Most notably, under realistic hardware configurations we predict that the largest models of CYP can be simulated with under 100 h of quantum computer time using approximately 5 million qubits implementing 7.8 × 10<sup>9</sup> Toffoli gates using four T factories. A direct runtime comparison of qubitized phase estimation shows a more favorable scaling than DMRG, in terms of bond dimension, and indicates future devices can potentially outperform classical machines when computing ground-state energies. Extrapolating the observed resource estimates to the full Cpd I system and compiling to the surface code indicate that a direct simulation of the entire system could require 1.5 trillion Toffoli gates—an unfeasible number of Toffoli gates to perform.
</blockquote>

<p>
(A Toffoli gate is a three-qubit operator, described nicely <a href=https://www.sharetechnote.com/html/QC/QuantumComputing_Gate_Toffoli.html>here</a>.)
</p>

<p>
Given that <a href=https://www.newscientist.com/article/2346074-ibm-unveils-worlds-largest-quantum-computer-at-433-qubits/>the largest quantum computer yet built is 433 qubits</a>, it’s clear that there’s a lot of work left to do until we can use quantum computers to inaugurate “a new era of discovery in chemistry.”
</p>

<figure>
  <img class=centered-img src=https://www.oezratty.net/wordpress/wp-content/IBM-Osprey-1024x989.jpg style="width:350px;" />
  <figcaption>
    433 qubits down, only 8 billion more to go
  </figcaption>
</figure>

<p>
<a href=https://arxiv.org/pdf/2310.03011.pdf#page34>A recent review</a> agrees with this assessment: the authors write that “there is currently no evidence that heuristic NISQ approaches [like VQE] will be able to scale to large system sizes and provide advantage over classical methods,” and conclude with this paragraph:
</p>

<blockquote>
Solving the electronic structure problem has repeatedly been identified as one of the most promising applications for quantum computers. Nevertheless, the discussion above highlights a number of challenges for current quantum approaches to become practical. Most notably, after accounting for the approximations typically made (i.e. incorporating the cost of initial state preparation, using nonminimal basis sets, including repetitions for correctness checking and sampling a range of parameters), a large number of logical qubits and total T/Toffoli gates are required. A major difficulty is that, unlike problems such as factoring, the end-to-end electronic structure problem typically requires solving a large number of closely related problem instances.
</blockquote>

<p>
An important thing to note, which the above paragraph alludes to, is that the specific quantum algorithms discussed here don't actually make quantum chemistry faster than today’s methods—they typically rely on a Hartree–Fock ansatz, which is about the same amount of work as a DFT calculation. Since it's likely that proper treatment of electron correlation will require a sizable basis set, much like we see with coupled-cluster theory, we can presume that quantum methods would be slower than most DFT methods (even assuming that the actual quantum part of the calculation could be run instantly).
</p>

<p>
This ignores the fact that the quantum methods would of course give much better results—but an uncomfortable truth is that, unlike one might think from the exuberant press releases quoted above, classical algorithms generally do an exceptional job already. Most molecules are very simple from an electronic structure perspective: static electron correlation is pretty rare, and linear scaling CCSD(T) approaches are widely available and very effective (<a href=https://pubs.acs.org/doi/abs/10.1021/acs.jctc.5b00359>e.g.</a>). There’s simply no need for FCI-quality results for most chemical problems, <a href=https://arxiv.org/pdf/2009.08927.pdf>random exceptions notwithstanding</a>.
</p>

<p>
(Aspuru-Guzik and co-workers agree; <a href=https://link.aps.org/accepted/10.1103/RevModPhys.92.015003>in a 2020 review</a>, they state that they “do not expect [HF and DFT] calculations to be replaced by those on quantum computers, given the large system sizes that are simulated,” suggesting instead that quantum computers might find utility for statically correlated systems with 100+ spin orbitals)
</p>

<p>
A related point I made in a <a href=https://rowansci.substack.com/p/quantum-chemistry-in-drug-discovery>recent essay/white paper for Rowan</a> is that quantum chemistry, at least as it’s applied to drug discovery, is limited not by accuracy but by speed. Existing quantum chemistry methods are already far more accurate than state-of-the-art drug discovery methods; replacing them with quantum computing-based approaches is like worrying about whether to bring a Lamborghini or a Formula 1 car to a go-kart race. It’s almost certain that there’s some way that “perfect” electronic structure calculations could be useful in drug design, but it’s hardly trivial to figure out how to turn a bunch of VQE calculations into a clinical candidate.
</p>

<p>
Other fields, like materials science, seem to be more limited by inaccuracies in theory—modeling metals and surfaces is really hard—but the Hartree–Fock ansatz is also hard here, and there are fewer commercial precedents for computational chemistry in general. To my knowledge, the Hartree–Fock starting point alone is a terrific challenge for a system like e.g. a cube of 10,000 metal atoms, which is why so many materials scientists avoid exact exchange and stick to local functionals. (I don't know much about computations on periodic systems, though, so correct me if this is wrong!) Using quantum computing to design superconducting materials probably won’t be <a href=https://twitter.com/RokoMijic/status/1684831855411961857>as easy as it seems on Twitter/X</a>.
</p>

<p>
So, while quantum computing is a terrifically exciting direction for computational chemistry in a scientific sense, I’m not sure it’s yet investable in a business sense. I don’t mean to belittle all the great scientific work being done in this field, in the papers I’ve referenced above and in many others. The point I’m trying to make here—that this field isn’t mature enough for actual commercial utility—could just as easily be made about ML in the 2000s, or any other number of promising but pre-commercial technologies. 
</p>

<p>
I’ll close by noting that it seems like markets are coming around to this perspective, too. Zapata Computing, one of the original “quantum computing for chemistry” companies, recently <a href=https://www.hpcwire.com/2023/09/07/quantum-hopeful-zapata-to-go-public-and-pivot-to-industrial-generative-ai/>pivoted</a> to… generative AI, going public via a SPAC with Andretti (motorsport), and IonQ recently <a href=https://www.businesswire.com/news/home/20231023981563/en/IonQ-Announces-Senior-Leadership-Transition>parted ways</a> with its CSO, who is going back to his faculty job at Duke. We’ll see what happens, but progress in hardware has been slow, and it’s likely that it’ll be years yet until we can start to perform practical quantum chemical calculations on quantum computers.
</p>

</div><div class='previous-link'><a href='blog_p5.html'>previous page</a></div><div class='next-link'><a href='blog_p7.html'>next page</a></div><br>
  </body>
  <br>
  <footer>
    <a href="mailto:corin.wagen+blog@gmail.com">email</a>
    <a href="https://github.com/corinwagen">github</a>
    <a href="https://twitter.com/CorinWagen">x</a>
    <a href="https://scholar.google.com/citations?user=SW0Uhs0AAAAJ">google scholar</a>
    <div style="float:right;">
      <a href="/rss.xml">rss</a>
      <a href="https://cwagen.substack.com">substack</a>
    </div>
  </footer>
</html>
